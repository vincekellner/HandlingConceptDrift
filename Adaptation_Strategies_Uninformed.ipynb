{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T11:50:48.476945Z",
     "start_time": "2020-01-23T11:50:48.471700Z"
    }
   },
   "source": [
    "This notebook provides two different strategies how incremental drift can be handled by applying uninformed adaptations. \n",
    "Strategies include:\n",
    "- 1) incremental training/updating of a model after a specific period (e.g. quarterly or yearly)\n",
    "- 2) training of a new model and discard old model after a specific period (e.g. quarterly or yearly)\n",
    "\n",
    "All strategies are applied with a custom feedforward MLP model & a custom LSTM model. Both models were trained to predict taxi demand in different areas in New York City at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:28.910493Z",
     "start_time": "2020-01-23T13:04:27.552258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "#from tqdm import tqdm\n",
    "\n",
    "\n",
    "#load custom deep Models (LSTM, MLP)\n",
    "from multivar_lstm import MultivariateLSTM\n",
    "\n",
    "from complex_mlp import ComplexMLP\n",
    "\n",
    "\n",
    "#import custom functions to store all kinds of results on disk:\n",
    "import save_files_collection as sv_files\n",
    "\n",
    "import regular_retraining_collection as rrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:31.767545Z",
     "start_time": "2020-01-23T13:04:28.927013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  1  2  3    4  5  6   7  8  9  ...  254  255  256  257  \\\n",
      "0 2009-01-01 05:00:00  0  0  0   91  0  0  30  0  0  ...    0   50   39    3   \n",
      "1 2009-01-01 06:00:00  1  0  0  105  0  0  62  0  0  ...    0   77   67    5   \n",
      "2 2009-01-01 07:00:00  0  0  0   96  0  0  79  0  0  ...    0   90   83    4   \n",
      "3 2009-01-01 08:00:00  0  0  0   91  0  0  84  0  0  ...    0   54   77    3   \n",
      "4 2009-01-01 09:00:00  2  0  0   82  0  0  85  0  1  ...    0   66   54    4   \n",
      "\n",
      "   258  259  260  261  262  263  \n",
      "0    1    0    3   52  127  326  \n",
      "1    0    0   15   65  166  476  \n",
      "2    0    0   19   39  125  460  \n",
      "3    1    0   19   54   79  313  \n",
      "4    0    0   13   24   47  224  \n",
      "\n",
      "[5 rows x 264 columns]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "TRAIN_PATH = '/media/...'\n",
    "Store_PATH = '/media/...'\n",
    "file_final = 'preprocessed_data.csv'\n",
    "\n",
    "df_m = pd.read_csv(TRAIN_PATH + file_final, header=0)\n",
    "\n",
    "#convert to datetime format:\n",
    "df_m['date'] = pd.to_datetime(df_m['date'], utc=True)\n",
    "df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_m['date'] = pd.to_datetime(df_m['date'])\n",
    "#df_m = df_m.set_index(\"date\") -> set index later, since we need \"date\" column to find highest demand columns..\n",
    "print(df_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:31.873020Z",
     "start_time": "2020-01-23T13:04:31.868194Z"
    }
   },
   "outputs": [],
   "source": [
    "'''filter areas with highest demand '''\n",
    "#get time series with highest \"demand patterns\":\n",
    "\n",
    "#function filters nlargest areas:\n",
    "def get_nlargest_areas(nlargest, org_dataset = df_m):\n",
    "    \n",
    "    #get time series with highest \"demand patterns\":\n",
    "    df_sum = org_dataset.copy(deep=True).drop(columns=[\"date\"],axis=1)\n",
    "    df_sum = df_sum.sum(axis=0,numeric_only=True)\n",
    "\n",
    "    #store nlargest values:\n",
    "    df_sum = df_sum.nlargest(nlargest) \n",
    "    idx_filter = list(df_sum.index.values)\n",
    "    #append \"date\" column\n",
    "    idx_filter.append(\"date\")\n",
    "\n",
    "    del df_sum\n",
    "    \n",
    "    #filter columns with largest values:\n",
    "    ts_largest = org_dataset[idx_filter].copy(deep=True)\n",
    "    ts_largest = ts_largest.set_index(\"date\")\n",
    "\n",
    "    #shift datetimeindex to use local NYC time not UTC:\n",
    "    ts_largest.index = ts_largest.index.shift(-5,freq='H')\n",
    "\n",
    "    return ts_largest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:32.384567Z",
     "start_time": "2020-01-23T13:04:31.937523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 largest areas:  (83231, 20)\n",
      "10 largest areas:  (83231, 10)\n"
     ]
    }
   ],
   "source": [
    "ts_20largest = get_nlargest_areas(20)\n",
    "ts_10largest = get_nlargest_areas(10)\n",
    "\n",
    "print('20 largest areas: ', ts_20largest.shape)\n",
    "print('10 largest areas: ', ts_10largest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:32.508437Z",
     "start_time": "2020-01-23T13:04:32.501496Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model_from_disk(model_type):\n",
    "    \n",
    "    '''\n",
    "    Returns pre-trained model from disk\n",
    "    '''\n",
    "\n",
    "\n",
    "    model_PATH = '/media/...'\n",
    "\n",
    "    #complex MLP:\n",
    "    model_architecture_complex_MLP_PATH = '/media/...'    \n",
    "    complex_MLP_model_file = 'complex_MLP_early_stopping_W168_20areas__y2012.json'\n",
    "    complex_MLP_weights = 'complex_MLP_early_stopping_W168_20areas__y2012_weights.h5'\n",
    "    \n",
    "    #multivar LSTM without additional features:\n",
    "    #prepare files for models:\n",
    "    model_architecture_multivar_20 = '/media/...'\n",
    "\n",
    "    multivar_LSTM_file = 'multivar_LSTM_W168_20areas__y2012.json'\n",
    "    multivar_LSTM_weights = 'multivar_LSTM_W168_20areas__y2012_weights.h5'\n",
    "\n",
    "        \n",
    "    instances_dict = {'SingleMLP': (),\n",
    "                  'SingleLSTM': (),\n",
    "                  'ComplexMLP': (complex_MLP_model_file, model_architecture_complex_MLP_PATH, complex_MLP_weights),\n",
    "                  'MultivarLSTM': (multivar_LSTM_file, model_architecture_multivar_20, multivar_LSTM_weights),                \n",
    "                 }\n",
    "    \n",
    "       \n",
    "    \n",
    "\n",
    "    #load complexMLP model 20largest areas:\n",
    "    json_file = open(model_PATH + instances_dict[model_type][0], 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    prediction_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    #load weights of best model:\n",
    "    prediction_model.load_weights(instances_dict[model_type][1] + instances_dict[model_type][2])\n",
    "\n",
    "\n",
    "    \n",
    "    return prediction_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function to create new model instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:04:32.630264Z",
     "start_time": "2020-01-23T13:04:32.626401Z"
    }
   },
   "outputs": [],
   "source": [
    "#function needed to create new instances, otherwise same instances is used!!\n",
    "def create_model_instance(model_type):\n",
    "    \n",
    "    instances_dict = {'ComplexMLP': ComplexMLP(),\n",
    "                      'MultivarLSTM': MultivariateLSTM(),\n",
    "                      'MultivarLSTM encoded': MultivariateLSTM(use_features_per_lag_flag = True, n_hidden_neurons_2 = 128),\n",
    "                     }\n",
    "    \n",
    "    return instances_dict[model_type]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultivarLSTM Model\n",
    "- without lagged features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy: Train new model on a quarterly basis\n",
    "- Params for test purpose: n_epochs = 5, end of dataset: 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:30:55.787479Z",
     "start_time": "2020-01-23T13:25:41.886048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: \"loaded\" model must have identical params as the Class currently has\n",
      "Forecasting based on given months is used...\n",
      "Shifting Window based on given months is used:  3\n",
      "Retraining range based on years:  2\n",
      "## Very first predictions with given pre-defined model are made..\n",
      "months to predict:  3\n",
      "## Assigned Dates are double checked..\n",
      "selected years for training:  ['2009', Timestamp('2010-12-31 23:00:00')]\n",
      "year_list given:  ['2009', Timestamp('2010-12-31 23:00:00'), '2011-01-01 00:00:00', None]\n",
      "#### Make predictions model: multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly ####\n",
      "2160/2160 [==============================] - 12s 6ms/step\n",
      "Shape of org. dataset after shift:  (2160, 20)\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:26:03\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00'), Timestamp('2011-04-01 00:00:00'), None]\n",
      "#### Train model: multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create stacked LSTM 2 layer non-stateful model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Regular 2H-LSTM Model is created...\n",
      "Train on 17351 samples, validate on 2184 samples\n",
      "Epoch 1/5\n",
      "17351/17351 [==============================] - 17s 961us/step - loss: 0.0352 - mean_absolute_error: 0.1401 - val_loss: 0.0304 - val_mean_absolute_error: 0.1274\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03036, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 2/5\n",
      "17351/17351 [==============================] - 14s 812us/step - loss: 0.0258 - mean_absolute_error: 0.1177 - val_loss: 0.0250 - val_mean_absolute_error: 0.1157\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03036 to 0.02502, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 3/5\n",
      "17351/17351 [==============================] - 14s 817us/step - loss: 0.0222 - mean_absolute_error: 0.1094 - val_loss: 0.0219 - val_mean_absolute_error: 0.1079\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02502 to 0.02189, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 4/5\n",
      "17351/17351 [==============================] - 14s 823us/step - loss: 0.0199 - mean_absolute_error: 0.1032 - val_loss: 0.0199 - val_mean_absolute_error: 0.1028\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02189 to 0.01987, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 5/5\n",
      "17351/17351 [==============================] - 14s 817us/step - loss: 0.0184 - mean_absolute_error: 0.0988 - val_loss: 0.0183 - val_mean_absolute_error: 0.0985\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01987 to 0.01826, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "2184/2184 [==============================] - 12s 5ms/step\n",
      "Shape of org. dataset after shift:  (2184, 20)\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:27:40\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00'), Timestamp('2011-07-01 00:00:00'), None]\n",
      "#### Train model: multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create stacked LSTM 2 layer non-stateful model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Regular 2H-LSTM Model is created...\n",
      "Train on 17351 samples, validate on 2208 samples\n",
      "Epoch 1/5\n",
      "17351/17351 [==============================] - 16s 938us/step - loss: 0.0375 - mean_absolute_error: 0.1449 - val_loss: 0.0268 - val_mean_absolute_error: 0.1179\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02678, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 2/5\n",
      "17351/17351 [==============================] - 14s 827us/step - loss: 0.0270 - mean_absolute_error: 0.1206 - val_loss: 0.0217 - val_mean_absolute_error: 0.1069\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02678 to 0.02165, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 3/5\n",
      "17351/17351 [==============================] - 14s 825us/step - loss: 0.0229 - mean_absolute_error: 0.1115 - val_loss: 0.0199 - val_mean_absolute_error: 0.1026\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02165 to 0.01986, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 4/5\n",
      "17351/17351 [==============================] - 14s 818us/step - loss: 0.0206 - mean_absolute_error: 0.1049 - val_loss: 0.0185 - val_mean_absolute_error: 0.0973\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01986 to 0.01850, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 5/5\n",
      "17351/17351 [==============================] - 14s 811us/step - loss: 0.0191 - mean_absolute_error: 0.1009 - val_loss: 0.0173 - val_mean_absolute_error: 0.0939\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01850 to 0.01733, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011_bestmodel.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208/2208 [==============================] - 12s 5ms/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:29:17\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00'), Timestamp('2011-10-01 00:00:00'), None]\n",
      "#### Train model: multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create stacked LSTM 2 layer non-stateful model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Regular 2H-LSTM Model is created...\n",
      "Train on 17351 samples, validate on 2208 samples\n",
      "Epoch 1/5\n",
      "17351/17351 [==============================] - 16s 945us/step - loss: 0.0390 - mean_absolute_error: 0.1478 - val_loss: 0.0315 - val_mean_absolute_error: 0.1290\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03146, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 2/5\n",
      "17351/17351 [==============================] - 14s 833us/step - loss: 0.0285 - mean_absolute_error: 0.1239 - val_loss: 0.0259 - val_mean_absolute_error: 0.1176\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03146 to 0.02590, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 3/5\n",
      "17351/17351 [==============================] - 14s 821us/step - loss: 0.0246 - mean_absolute_error: 0.1155 - val_loss: 0.0231 - val_mean_absolute_error: 0.1112\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02590 to 0.02313, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 4/5\n",
      "17351/17351 [==============================] - 14s 825us/step - loss: 0.0221 - mean_absolute_error: 0.1089 - val_loss: 0.0213 - val_mean_absolute_error: 0.1070\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02313 to 0.02127, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "Epoch 5/5\n",
      "17351/17351 [==============================] - 14s 823us/step - loss: 0.0204 - mean_absolute_error: 0.1043 - val_loss: 0.0196 - val_mean_absolute_error: 0.1025\n",
      "#Current LearningRate:  0.001\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02127 to 0.01964, saving model to /media/vincent/harddrive/ML-Projects_all/NY_Cab_Project/NY_Cab_Data/results/Stacked_LSTM/Hyperparam_tuning_y2011/Best_Models/multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011_bestmodel.h5\n",
      "2208/2208 [==============================] - 12s 5ms/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:30:55\n",
      "## Assigned Dates are double checked..\n",
      "Stop retraining scheme >> end of data set or end of predictions are reached\n",
      " >> Number of predictions with existing model:  1\n",
      " >> Number of retrainings:  3\n"
     ]
    }
   ],
   "source": [
    "#set model_name based on used params:\n",
    "model_name = 'multivar_lstm_2H_256_32_batch512_drop03_clip_norm_shuffle_scaling_tanh_W168_20largest_areas_reg_retrain_quarterly' \n",
    "\n",
    "#create instance of class:\n",
    "multiLSTM_model_new = create_model_instance('MultivarLSTM')\n",
    "\n",
    "#update instance with model from disk:\n",
    "prediction_model = load_pretrained_model_from_disk('MultivarLSTM')\n",
    "multiLSTM_model_new.load_model(prediction_model)\n",
    "\n",
    "#set dataset for slicing:\n",
    "ts_series_input = ts_20largest.copy()\n",
    "\n",
    "\n",
    "\n",
    "#call function for drift detection & retraining:\n",
    "results_tuple_multiLSTM_retrain = rrc.regular_retraining_scheme(multiLSTM_model_new, org_ts_series=ts_series_input, model_name=model_name, \n",
    "                                          n_epochs_retrain = 5, update_weights_flag = False, overwrite_params = True,\n",
    "                                          start_date_training = '2009', last_date_training = '2010', \n",
    "                                          first_date_dataset = '2009-01-01 00:00:00',\n",
    "                                          start_of_preds_date = '2011-01-01 00:00:00',\n",
    "                                          end_of_dataset_date = '2011-12-31 23:00:00',\n",
    "                                          forecast_range_months = 3, \n",
    "                                          retrain_shifting_window_months = 3,\n",
    "                                          month_forecasting = True,\n",
    "                                          retrain_shifting_window_flag_day = False,\n",
    "                                          retraining_range_years = 2,\n",
    "                                          first_preds_flag = False,           \n",
    "                                          verbosity=0)\n",
    "                               \n",
    "\n",
    "      \n",
    "    \n",
    "all_multiLSTM_MODELS_dict_retrain = results_tuple_multiLSTM_retrain[0]\n",
    "all_multiLSTM_RESULTS_dict_retrain = results_tuple_multiLSTM_retrain[1]\n",
    "all_multiLSTM_results_retrain = results_tuple_multiLSTM_retrain[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store predictions on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store models & history on disk:\n",
    "\n",
    "model_save_PATH = '/media/...'\n",
    "df_save_PATH = '/media/...'\n",
    "\n",
    "#call function to store models & history on disk:\n",
    "_ = sv_files.store_model_and_history_on_disk(all_multiLSTM_MODELS_dict_retrain, model_save_PATH, df_save_PATH)\n",
    "\n",
    "#call function to store prediction results:\n",
    "_ = sv_files.store_retrained_predictions(all_multiLSTM_RESULTS_dict_retrain, all_multiLSTM_MODELS_dict_retrain, df_save_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy: Train new model on a quarterly basis\n",
    "- Params for test purpose: n_epochs = 5, end of dataset: 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:08:07.334158Z",
     "start_time": "2020-01-23T13:06:15.498550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting based on given months is used...\n",
      "Shifting Window based on given months is used:  3\n",
      "Retraining range based on years:  2\n",
      "## Very first predictions with given pre-defined model are made..\n",
      "months to predict:  3\n",
      "## Assigned Dates are double checked..\n",
      "selected years for training:  ['2009', Timestamp('2010-12-31 23:00:00')]\n",
      "year_list given:  ['2009', Timestamp('2010-12-31 23:00:00'), '2011-01-01 00:00:00', None]\n",
      "#### Make predictions model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_quarterly ####\n",
      "43200/43200 [==============================] - 1s 20us/step\n",
      "Shape of org. dataset after shift:  (2160, 20)\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:06:26\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00'), Timestamp('2011-04-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create MLP Model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Train on 336940 samples, validate on 43680 samples\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.3881 - mean_absolute_error: 0.4465 - val_loss: 0.2520 - val_mean_absolute_error: 0.3612\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2937 - mean_absolute_error: 0.3888 - val_loss: 0.2277 - val_mean_absolute_error: 0.3403\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2746 - mean_absolute_error: 0.3752 - val_loss: 0.2193 - val_mean_absolute_error: 0.3310\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2633 - mean_absolute_error: 0.3668 - val_loss: 0.2150 - val_mean_absolute_error: 0.3291\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2556 - mean_absolute_error: 0.3609 - val_loss: 0.2099 - val_mean_absolute_error: 0.3242\n",
      "#Current LearningRate:  0.001\n",
      "43680/43680 [==============================] - 1s 22us/step\n",
      "Shape of org. dataset after shift:  (2184, 20)\n",
      "20/20 [==============================] - 0s 43us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:07:00\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00'), Timestamp('2011-07-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create MLP Model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Train on 336940 samples, validate on 44160 samples\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.3693 - mean_absolute_error: 0.4383 - val_loss: 0.2492 - val_mean_absolute_error: 0.3555\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2894 - mean_absolute_error: 0.3876 - val_loss: 0.2246 - val_mean_absolute_error: 0.3351\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2704 - mean_absolute_error: 0.3732 - val_loss: 0.2190 - val_mean_absolute_error: 0.3305\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2579 - mean_absolute_error: 0.3641 - val_loss: 0.2111 - val_mean_absolute_error: 0.3237\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2495 - mean_absolute_error: 0.3579 - val_loss: 0.2056 - val_mean_absolute_error: 0.3176\n",
      "#Current LearningRate:  0.001\n",
      "44160/44160 [==============================] - 1s 23us/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "20/20 [==============================] - 0s 44us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:07:33\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00'), Timestamp('2011-10-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create MLP Model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Train on 336940 samples, validate on 44160 samples\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.3900 - mean_absolute_error: 0.4496 - val_loss: 0.2920 - val_mean_absolute_error: 0.3889\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2922 - mean_absolute_error: 0.3895 - val_loss: 0.2669 - val_mean_absolute_error: 0.3697\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2723 - mean_absolute_error: 0.3748 - val_loss: 0.2518 - val_mean_absolute_error: 0.3574\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2631 - mean_absolute_error: 0.3672 - val_loss: 0.2476 - val_mean_absolute_error: 0.3554\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2554 - mean_absolute_error: 0.3622 - val_loss: 0.2390 - val_mean_absolute_error: 0.3477\n",
      "#Current LearningRate:  0.001\n",
      "44160/44160 [==============================] - 1s 24us/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "20/20 [==============================] - 0s 41us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:08:07\n",
      "## Assigned Dates are double checked..\n",
      "Stop retraining scheme >> end of data set or end of predictions are reached\n",
      " >> Number of predictions with existing model:  1\n",
      " >> Number of retrainings:  3\n"
     ]
    }
   ],
   "source": [
    "#set model_name based on used params:\n",
    "model_name = 'complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_quarterly'\n",
    "\n",
    "\n",
    "#create instance of class:\n",
    "cplxMLP_model_new = create_model_instance('ComplexMLP')\n",
    "\n",
    "#update instance with model from disk:\n",
    "prediction_model = load_pretrained_model_from_disk('ComplexMLP')\n",
    "cplxMLP_model_new.load_model(prediction_model)\n",
    "\n",
    "#set dataset for slicing:\n",
    "ts_series_input = ts_20largest.copy()\n",
    "\n",
    "\n",
    "\n",
    "#call function for drift detection & retraining:\n",
    "results_tuple_MLP_retrain = rrc.regular_retraining_scheme(cplxMLP_model_new, org_ts_series=ts_series_input, model_name=model_name, \n",
    "                                          n_epochs_retrain = 5, update_weights_flag = False, overwrite_params = True,\n",
    "                                          start_date_training = '2009', last_date_training = '2010', \n",
    "                                          first_date_dataset = '2009-01-01 00:00:00',\n",
    "                                          start_of_preds_date = '2011-01-01 00:00:00',\n",
    "                                          end_of_dataset_date = '2011-12-31 23:00:00',\n",
    "                                          forecast_range_months = 3, \n",
    "                                          retrain_shifting_window_months = 3,\n",
    "                                          month_forecasting = True,\n",
    "                                          retrain_shifting_window_flag_day = False,\n",
    "                                          retraining_range_years = 2,\n",
    "                                          first_preds_flag = False,           \n",
    "                                          verbosity=0)\n",
    "                               \n",
    "\n",
    "      \n",
    "    \n",
    "all_cplxMLP_MODELS_dict_retrain = results_tuple_MLP_retrain[0]\n",
    "all_cplxMLP_RESULTS_dict_retrain = results_tuple_MLP_retrain[1]\n",
    "all_cplxMLP_RMSE_results_retrain = results_tuple_MLP_retrain[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T00:09:26.166828Z",
     "start_time": "2019-09-24T00:09:22.602334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "Saved model to disk\n",
      "Save history_df on disk done\n",
      "predictions stored on disk!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>237</th>\n",
       "      <th>161</th>\n",
       "      <th>230</th>\n",
       "      <th>79</th>\n",
       "      <th>236</th>\n",
       "      <th>162</th>\n",
       "      <th>170</th>\n",
       "      <th>234</th>\n",
       "      <th>48</th>\n",
       "      <th>186</th>\n",
       "      <th>142</th>\n",
       "      <th>107</th>\n",
       "      <th>163</th>\n",
       "      <th>68</th>\n",
       "      <th>239</th>\n",
       "      <th>164</th>\n",
       "      <th>141</th>\n",
       "      <th>249</th>\n",
       "      <th>138</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>378.765518</td>\n",
       "      <td>357.815909</td>\n",
       "      <td>170.954948</td>\n",
       "      <td>1169.934412</td>\n",
       "      <td>442.598282</td>\n",
       "      <td>377.660637</td>\n",
       "      <td>550.033426</td>\n",
       "      <td>629.927204</td>\n",
       "      <td>595.273397</td>\n",
       "      <td>309.469646</td>\n",
       "      <td>471.259277</td>\n",
       "      <td>729.279806</td>\n",
       "      <td>207.935535</td>\n",
       "      <td>590.287590</td>\n",
       "      <td>428.227081</td>\n",
       "      <td>418.747496</td>\n",
       "      <td>397.209515</td>\n",
       "      <td>592.011109</td>\n",
       "      <td>253.741570</td>\n",
       "      <td>465.114122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>181.884430</td>\n",
       "      <td>168.474030</td>\n",
       "      <td>42.926036</td>\n",
       "      <td>622.392572</td>\n",
       "      <td>233.041191</td>\n",
       "      <td>168.738678</td>\n",
       "      <td>419.629261</td>\n",
       "      <td>424.060136</td>\n",
       "      <td>353.670305</td>\n",
       "      <td>125.292004</td>\n",
       "      <td>222.339844</td>\n",
       "      <td>448.033763</td>\n",
       "      <td>106.633280</td>\n",
       "      <td>385.276383</td>\n",
       "      <td>219.484436</td>\n",
       "      <td>272.536284</td>\n",
       "      <td>282.326519</td>\n",
       "      <td>351.437659</td>\n",
       "      <td>17.621679</td>\n",
       "      <td>298.460461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>241.671692</td>\n",
       "      <td>96.039963</td>\n",
       "      <td>29.937252</td>\n",
       "      <td>584.864774</td>\n",
       "      <td>250.420319</td>\n",
       "      <td>212.491394</td>\n",
       "      <td>414.283463</td>\n",
       "      <td>259.114410</td>\n",
       "      <td>279.256687</td>\n",
       "      <td>142.871590</td>\n",
       "      <td>193.208305</td>\n",
       "      <td>429.281321</td>\n",
       "      <td>89.379490</td>\n",
       "      <td>309.107438</td>\n",
       "      <td>298.728119</td>\n",
       "      <td>264.542053</td>\n",
       "      <td>345.457260</td>\n",
       "      <td>247.204753</td>\n",
       "      <td>-33.437027</td>\n",
       "      <td>207.911047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>189.511894</td>\n",
       "      <td>167.290459</td>\n",
       "      <td>10.560440</td>\n",
       "      <td>472.070137</td>\n",
       "      <td>229.376633</td>\n",
       "      <td>216.780785</td>\n",
       "      <td>359.250160</td>\n",
       "      <td>144.219376</td>\n",
       "      <td>231.996140</td>\n",
       "      <td>101.239594</td>\n",
       "      <td>164.243835</td>\n",
       "      <td>317.994476</td>\n",
       "      <td>102.161911</td>\n",
       "      <td>305.833828</td>\n",
       "      <td>284.499657</td>\n",
       "      <td>174.675640</td>\n",
       "      <td>280.474159</td>\n",
       "      <td>220.177378</td>\n",
       "      <td>4.844269</td>\n",
       "      <td>167.948177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>110.338257</td>\n",
       "      <td>136.352837</td>\n",
       "      <td>83.788517</td>\n",
       "      <td>416.465500</td>\n",
       "      <td>116.343174</td>\n",
       "      <td>176.087357</td>\n",
       "      <td>271.892715</td>\n",
       "      <td>120.585670</td>\n",
       "      <td>314.153542</td>\n",
       "      <td>150.121731</td>\n",
       "      <td>152.050491</td>\n",
       "      <td>315.191330</td>\n",
       "      <td>107.946434</td>\n",
       "      <td>203.333633</td>\n",
       "      <td>174.203522</td>\n",
       "      <td>194.469173</td>\n",
       "      <td>225.335232</td>\n",
       "      <td>149.999481</td>\n",
       "      <td>7.342397</td>\n",
       "      <td>201.800657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>62.164257</td>\n",
       "      <td>54.906208</td>\n",
       "      <td>89.495232</td>\n",
       "      <td>259.148331</td>\n",
       "      <td>61.549626</td>\n",
       "      <td>110.638420</td>\n",
       "      <td>148.955566</td>\n",
       "      <td>99.215950</td>\n",
       "      <td>213.046333</td>\n",
       "      <td>97.153419</td>\n",
       "      <td>82.878651</td>\n",
       "      <td>241.789742</td>\n",
       "      <td>43.310005</td>\n",
       "      <td>122.863838</td>\n",
       "      <td>110.274092</td>\n",
       "      <td>141.823845</td>\n",
       "      <td>125.010246</td>\n",
       "      <td>128.085880</td>\n",
       "      <td>7.036086</td>\n",
       "      <td>144.025841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>66.781725</td>\n",
       "      <td>61.357931</td>\n",
       "      <td>134.885628</td>\n",
       "      <td>295.728729</td>\n",
       "      <td>87.218090</td>\n",
       "      <td>70.971793</td>\n",
       "      <td>112.930840</td>\n",
       "      <td>100.278843</td>\n",
       "      <td>231.373892</td>\n",
       "      <td>102.563267</td>\n",
       "      <td>88.324356</td>\n",
       "      <td>113.528565</td>\n",
       "      <td>73.603363</td>\n",
       "      <td>72.584560</td>\n",
       "      <td>72.351177</td>\n",
       "      <td>123.736671</td>\n",
       "      <td>89.766273</td>\n",
       "      <td>121.528501</td>\n",
       "      <td>17.609750</td>\n",
       "      <td>94.061470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>84.726795</td>\n",
       "      <td>67.493668</td>\n",
       "      <td>153.786304</td>\n",
       "      <td>298.408325</td>\n",
       "      <td>82.917557</td>\n",
       "      <td>86.868332</td>\n",
       "      <td>103.207989</td>\n",
       "      <td>100.012419</td>\n",
       "      <td>156.731279</td>\n",
       "      <td>110.103443</td>\n",
       "      <td>75.645695</td>\n",
       "      <td>121.926693</td>\n",
       "      <td>78.401155</td>\n",
       "      <td>132.896870</td>\n",
       "      <td>85.122429</td>\n",
       "      <td>102.120327</td>\n",
       "      <td>71.124947</td>\n",
       "      <td>133.895611</td>\n",
       "      <td>40.226765</td>\n",
       "      <td>123.242514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>101.432892</td>\n",
       "      <td>100.571232</td>\n",
       "      <td>163.821236</td>\n",
       "      <td>195.815018</td>\n",
       "      <td>127.228683</td>\n",
       "      <td>88.336998</td>\n",
       "      <td>128.774742</td>\n",
       "      <td>111.582752</td>\n",
       "      <td>175.556850</td>\n",
       "      <td>121.871658</td>\n",
       "      <td>107.839367</td>\n",
       "      <td>123.028694</td>\n",
       "      <td>80.145538</td>\n",
       "      <td>124.796234</td>\n",
       "      <td>110.470451</td>\n",
       "      <td>99.240084</td>\n",
       "      <td>119.437119</td>\n",
       "      <td>89.794327</td>\n",
       "      <td>78.869400</td>\n",
       "      <td>92.342709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>121.160362</td>\n",
       "      <td>116.529305</td>\n",
       "      <td>163.194427</td>\n",
       "      <td>195.470207</td>\n",
       "      <td>143.858780</td>\n",
       "      <td>121.915550</td>\n",
       "      <td>144.180702</td>\n",
       "      <td>122.628166</td>\n",
       "      <td>198.226601</td>\n",
       "      <td>129.227875</td>\n",
       "      <td>165.387985</td>\n",
       "      <td>117.207775</td>\n",
       "      <td>80.417599</td>\n",
       "      <td>125.327011</td>\n",
       "      <td>161.142014</td>\n",
       "      <td>90.730434</td>\n",
       "      <td>115.199486</td>\n",
       "      <td>94.248634</td>\n",
       "      <td>119.996246</td>\n",
       "      <td>96.119381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 10:00:00</th>\n",
       "      <td>210.421906</td>\n",
       "      <td>211.488251</td>\n",
       "      <td>221.520355</td>\n",
       "      <td>235.293434</td>\n",
       "      <td>212.556702</td>\n",
       "      <td>195.916382</td>\n",
       "      <td>218.488708</td>\n",
       "      <td>146.403275</td>\n",
       "      <td>232.650986</td>\n",
       "      <td>183.310333</td>\n",
       "      <td>189.803505</td>\n",
       "      <td>174.052467</td>\n",
       "      <td>180.632423</td>\n",
       "      <td>138.809082</td>\n",
       "      <td>206.041893</td>\n",
       "      <td>149.250412</td>\n",
       "      <td>173.798149</td>\n",
       "      <td>118.917366</td>\n",
       "      <td>189.833778</td>\n",
       "      <td>116.565098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 11:00:00</th>\n",
       "      <td>264.718620</td>\n",
       "      <td>278.072281</td>\n",
       "      <td>260.599747</td>\n",
       "      <td>214.679779</td>\n",
       "      <td>240.494743</td>\n",
       "      <td>246.029572</td>\n",
       "      <td>277.038132</td>\n",
       "      <td>173.997864</td>\n",
       "      <td>201.748627</td>\n",
       "      <td>253.915451</td>\n",
       "      <td>226.565849</td>\n",
       "      <td>202.942123</td>\n",
       "      <td>210.748589</td>\n",
       "      <td>181.676880</td>\n",
       "      <td>228.131721</td>\n",
       "      <td>173.112328</td>\n",
       "      <td>222.232376</td>\n",
       "      <td>161.172516</td>\n",
       "      <td>175.700504</td>\n",
       "      <td>150.635780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 12:00:00</th>\n",
       "      <td>315.979485</td>\n",
       "      <td>285.259010</td>\n",
       "      <td>299.419006</td>\n",
       "      <td>250.709694</td>\n",
       "      <td>315.425308</td>\n",
       "      <td>303.454735</td>\n",
       "      <td>328.073013</td>\n",
       "      <td>236.796822</td>\n",
       "      <td>266.555565</td>\n",
       "      <td>224.831696</td>\n",
       "      <td>263.467003</td>\n",
       "      <td>263.059372</td>\n",
       "      <td>223.240524</td>\n",
       "      <td>211.865387</td>\n",
       "      <td>329.763794</td>\n",
       "      <td>222.750519</td>\n",
       "      <td>253.387436</td>\n",
       "      <td>188.683861</td>\n",
       "      <td>208.724850</td>\n",
       "      <td>195.445396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 13:00:00</th>\n",
       "      <td>366.979446</td>\n",
       "      <td>329.070679</td>\n",
       "      <td>287.340218</td>\n",
       "      <td>301.168571</td>\n",
       "      <td>328.584091</td>\n",
       "      <td>310.146729</td>\n",
       "      <td>346.519516</td>\n",
       "      <td>277.514160</td>\n",
       "      <td>297.950352</td>\n",
       "      <td>259.552557</td>\n",
       "      <td>334.078354</td>\n",
       "      <td>273.790970</td>\n",
       "      <td>264.771416</td>\n",
       "      <td>241.050468</td>\n",
       "      <td>334.310555</td>\n",
       "      <td>233.139618</td>\n",
       "      <td>280.883537</td>\n",
       "      <td>193.336258</td>\n",
       "      <td>204.551811</td>\n",
       "      <td>223.744759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 14:00:00</th>\n",
       "      <td>350.638176</td>\n",
       "      <td>384.496162</td>\n",
       "      <td>300.278076</td>\n",
       "      <td>327.490860</td>\n",
       "      <td>326.107101</td>\n",
       "      <td>315.935982</td>\n",
       "      <td>314.594063</td>\n",
       "      <td>281.650734</td>\n",
       "      <td>293.062885</td>\n",
       "      <td>335.799675</td>\n",
       "      <td>324.501717</td>\n",
       "      <td>290.459682</td>\n",
       "      <td>313.129333</td>\n",
       "      <td>217.709747</td>\n",
       "      <td>292.675247</td>\n",
       "      <td>233.829376</td>\n",
       "      <td>249.666718</td>\n",
       "      <td>210.617985</td>\n",
       "      <td>181.458952</td>\n",
       "      <td>211.402687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 15:00:00</th>\n",
       "      <td>381.791397</td>\n",
       "      <td>358.231575</td>\n",
       "      <td>268.366526</td>\n",
       "      <td>314.510120</td>\n",
       "      <td>286.985786</td>\n",
       "      <td>297.677433</td>\n",
       "      <td>305.386459</td>\n",
       "      <td>270.785347</td>\n",
       "      <td>237.995687</td>\n",
       "      <td>258.674180</td>\n",
       "      <td>350.943344</td>\n",
       "      <td>250.369785</td>\n",
       "      <td>267.460201</td>\n",
       "      <td>206.399977</td>\n",
       "      <td>311.282410</td>\n",
       "      <td>214.228155</td>\n",
       "      <td>277.571480</td>\n",
       "      <td>219.789581</td>\n",
       "      <td>152.124468</td>\n",
       "      <td>192.987309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 16:00:00</th>\n",
       "      <td>326.586740</td>\n",
       "      <td>308.809441</td>\n",
       "      <td>327.177530</td>\n",
       "      <td>290.440400</td>\n",
       "      <td>289.070103</td>\n",
       "      <td>221.213147</td>\n",
       "      <td>297.489481</td>\n",
       "      <td>238.097770</td>\n",
       "      <td>247.380360</td>\n",
       "      <td>207.261833</td>\n",
       "      <td>304.320062</td>\n",
       "      <td>253.149476</td>\n",
       "      <td>223.537010</td>\n",
       "      <td>164.221707</td>\n",
       "      <td>291.681856</td>\n",
       "      <td>190.436602</td>\n",
       "      <td>255.695534</td>\n",
       "      <td>182.498240</td>\n",
       "      <td>193.556034</td>\n",
       "      <td>154.980534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 17:00:00</th>\n",
       "      <td>341.422798</td>\n",
       "      <td>322.741219</td>\n",
       "      <td>280.993858</td>\n",
       "      <td>352.455864</td>\n",
       "      <td>316.241249</td>\n",
       "      <td>247.207329</td>\n",
       "      <td>299.675949</td>\n",
       "      <td>264.049000</td>\n",
       "      <td>270.605270</td>\n",
       "      <td>253.063534</td>\n",
       "      <td>317.771507</td>\n",
       "      <td>244.479557</td>\n",
       "      <td>215.321370</td>\n",
       "      <td>181.392365</td>\n",
       "      <td>285.166294</td>\n",
       "      <td>193.945667</td>\n",
       "      <td>320.420021</td>\n",
       "      <td>217.987247</td>\n",
       "      <td>184.766660</td>\n",
       "      <td>196.200218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 18:00:00</th>\n",
       "      <td>341.244053</td>\n",
       "      <td>306.845074</td>\n",
       "      <td>316.409527</td>\n",
       "      <td>429.343079</td>\n",
       "      <td>301.216553</td>\n",
       "      <td>293.618177</td>\n",
       "      <td>358.656837</td>\n",
       "      <td>284.166855</td>\n",
       "      <td>352.777855</td>\n",
       "      <td>329.982674</td>\n",
       "      <td>393.319580</td>\n",
       "      <td>320.056221</td>\n",
       "      <td>222.804876</td>\n",
       "      <td>200.562378</td>\n",
       "      <td>311.303169</td>\n",
       "      <td>230.925793</td>\n",
       "      <td>323.323357</td>\n",
       "      <td>234.247375</td>\n",
       "      <td>197.124294</td>\n",
       "      <td>216.825577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 19:00:00</th>\n",
       "      <td>264.393866</td>\n",
       "      <td>336.588946</td>\n",
       "      <td>316.067490</td>\n",
       "      <td>502.199432</td>\n",
       "      <td>309.611843</td>\n",
       "      <td>268.336823</td>\n",
       "      <td>406.879822</td>\n",
       "      <td>313.281395</td>\n",
       "      <td>354.474747</td>\n",
       "      <td>350.384815</td>\n",
       "      <td>400.514313</td>\n",
       "      <td>336.833344</td>\n",
       "      <td>258.476542</td>\n",
       "      <td>283.561913</td>\n",
       "      <td>258.430707</td>\n",
       "      <td>265.027691</td>\n",
       "      <td>325.846344</td>\n",
       "      <td>322.735542</td>\n",
       "      <td>216.265659</td>\n",
       "      <td>249.125923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 20:00:00</th>\n",
       "      <td>267.187412</td>\n",
       "      <td>301.472530</td>\n",
       "      <td>231.311813</td>\n",
       "      <td>493.253799</td>\n",
       "      <td>290.896090</td>\n",
       "      <td>293.721948</td>\n",
       "      <td>414.278152</td>\n",
       "      <td>262.071064</td>\n",
       "      <td>367.300785</td>\n",
       "      <td>309.378915</td>\n",
       "      <td>310.984436</td>\n",
       "      <td>375.702324</td>\n",
       "      <td>203.714256</td>\n",
       "      <td>277.583893</td>\n",
       "      <td>228.946226</td>\n",
       "      <td>253.911221</td>\n",
       "      <td>284.669092</td>\n",
       "      <td>305.266815</td>\n",
       "      <td>122.268333</td>\n",
       "      <td>255.431992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 21:00:00</th>\n",
       "      <td>141.130562</td>\n",
       "      <td>220.736111</td>\n",
       "      <td>244.526550</td>\n",
       "      <td>413.584549</td>\n",
       "      <td>215.725537</td>\n",
       "      <td>202.197065</td>\n",
       "      <td>290.414399</td>\n",
       "      <td>223.754000</td>\n",
       "      <td>295.448334</td>\n",
       "      <td>279.255835</td>\n",
       "      <td>317.672386</td>\n",
       "      <td>285.174797</td>\n",
       "      <td>132.177114</td>\n",
       "      <td>221.120461</td>\n",
       "      <td>196.698016</td>\n",
       "      <td>204.624383</td>\n",
       "      <td>222.191813</td>\n",
       "      <td>273.912674</td>\n",
       "      <td>143.210379</td>\n",
       "      <td>187.391262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 22:00:00</th>\n",
       "      <td>125.368629</td>\n",
       "      <td>179.892929</td>\n",
       "      <td>334.013485</td>\n",
       "      <td>424.138651</td>\n",
       "      <td>181.149927</td>\n",
       "      <td>154.370926</td>\n",
       "      <td>197.302109</td>\n",
       "      <td>181.868769</td>\n",
       "      <td>410.831909</td>\n",
       "      <td>208.201893</td>\n",
       "      <td>327.136047</td>\n",
       "      <td>224.946512</td>\n",
       "      <td>156.130494</td>\n",
       "      <td>163.188511</td>\n",
       "      <td>155.358354</td>\n",
       "      <td>199.868029</td>\n",
       "      <td>185.462097</td>\n",
       "      <td>210.804609</td>\n",
       "      <td>194.105114</td>\n",
       "      <td>169.690871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 23:00:00</th>\n",
       "      <td>131.661415</td>\n",
       "      <td>105.858391</td>\n",
       "      <td>437.885292</td>\n",
       "      <td>436.778999</td>\n",
       "      <td>166.974571</td>\n",
       "      <td>99.741211</td>\n",
       "      <td>194.532898</td>\n",
       "      <td>217.459042</td>\n",
       "      <td>351.388763</td>\n",
       "      <td>207.140076</td>\n",
       "      <td>343.861663</td>\n",
       "      <td>268.505022</td>\n",
       "      <td>134.945267</td>\n",
       "      <td>176.980647</td>\n",
       "      <td>178.351964</td>\n",
       "      <td>185.561311</td>\n",
       "      <td>179.072845</td>\n",
       "      <td>229.096519</td>\n",
       "      <td>123.822205</td>\n",
       "      <td>141.373773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 00:00:00</th>\n",
       "      <td>55.905266</td>\n",
       "      <td>105.983238</td>\n",
       "      <td>300.193527</td>\n",
       "      <td>367.743668</td>\n",
       "      <td>77.498795</td>\n",
       "      <td>86.031029</td>\n",
       "      <td>209.765381</td>\n",
       "      <td>138.712593</td>\n",
       "      <td>251.548210</td>\n",
       "      <td>258.077316</td>\n",
       "      <td>194.236282</td>\n",
       "      <td>189.756264</td>\n",
       "      <td>103.759190</td>\n",
       "      <td>165.800964</td>\n",
       "      <td>100.871819</td>\n",
       "      <td>208.461800</td>\n",
       "      <td>115.800812</td>\n",
       "      <td>209.518257</td>\n",
       "      <td>120.369370</td>\n",
       "      <td>116.192848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 01:00:00</th>\n",
       "      <td>45.921829</td>\n",
       "      <td>46.107986</td>\n",
       "      <td>281.299320</td>\n",
       "      <td>502.949783</td>\n",
       "      <td>47.472668</td>\n",
       "      <td>90.936802</td>\n",
       "      <td>167.901207</td>\n",
       "      <td>198.260700</td>\n",
       "      <td>332.514687</td>\n",
       "      <td>232.868706</td>\n",
       "      <td>146.092514</td>\n",
       "      <td>295.379374</td>\n",
       "      <td>85.384705</td>\n",
       "      <td>222.072850</td>\n",
       "      <td>97.493496</td>\n",
       "      <td>242.553616</td>\n",
       "      <td>109.241611</td>\n",
       "      <td>253.544197</td>\n",
       "      <td>60.478054</td>\n",
       "      <td>131.872013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 02:00:00</th>\n",
       "      <td>11.945354</td>\n",
       "      <td>12.450943</td>\n",
       "      <td>222.016727</td>\n",
       "      <td>663.796368</td>\n",
       "      <td>19.233143</td>\n",
       "      <td>30.605087</td>\n",
       "      <td>131.117233</td>\n",
       "      <td>131.352795</td>\n",
       "      <td>244.937813</td>\n",
       "      <td>128.369022</td>\n",
       "      <td>55.573326</td>\n",
       "      <td>170.616825</td>\n",
       "      <td>67.268383</td>\n",
       "      <td>191.427484</td>\n",
       "      <td>80.006527</td>\n",
       "      <td>190.963463</td>\n",
       "      <td>54.370148</td>\n",
       "      <td>298.169636</td>\n",
       "      <td>4.517738</td>\n",
       "      <td>98.029636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 03:00:00</th>\n",
       "      <td>-16.884789</td>\n",
       "      <td>-22.616383</td>\n",
       "      <td>121.308712</td>\n",
       "      <td>697.478157</td>\n",
       "      <td>-5.059177</td>\n",
       "      <td>14.348747</td>\n",
       "      <td>122.727448</td>\n",
       "      <td>96.253059</td>\n",
       "      <td>183.537323</td>\n",
       "      <td>73.166492</td>\n",
       "      <td>32.011642</td>\n",
       "      <td>93.591557</td>\n",
       "      <td>51.762394</td>\n",
       "      <td>88.442436</td>\n",
       "      <td>64.470215</td>\n",
       "      <td>118.349018</td>\n",
       "      <td>31.011280</td>\n",
       "      <td>199.042923</td>\n",
       "      <td>25.637240</td>\n",
       "      <td>103.248489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 04:00:00</th>\n",
       "      <td>-19.448544</td>\n",
       "      <td>-8.468880</td>\n",
       "      <td>99.458595</td>\n",
       "      <td>338.882568</td>\n",
       "      <td>-9.391819</td>\n",
       "      <td>-2.070023</td>\n",
       "      <td>50.616608</td>\n",
       "      <td>63.739723</td>\n",
       "      <td>144.440643</td>\n",
       "      <td>14.333855</td>\n",
       "      <td>13.443787</td>\n",
       "      <td>57.648178</td>\n",
       "      <td>45.203697</td>\n",
       "      <td>89.829311</td>\n",
       "      <td>5.117950</td>\n",
       "      <td>68.114414</td>\n",
       "      <td>31.671753</td>\n",
       "      <td>97.615257</td>\n",
       "      <td>1.826038</td>\n",
       "      <td>61.033833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 05:00:00</th>\n",
       "      <td>6.229615</td>\n",
       "      <td>-2.304180</td>\n",
       "      <td>52.110916</td>\n",
       "      <td>184.504532</td>\n",
       "      <td>-7.107853</td>\n",
       "      <td>1.122986</td>\n",
       "      <td>4.986832</td>\n",
       "      <td>8.479103</td>\n",
       "      <td>95.472557</td>\n",
       "      <td>35.724979</td>\n",
       "      <td>-19.261410</td>\n",
       "      <td>6.922081</td>\n",
       "      <td>15.805103</td>\n",
       "      <td>53.903572</td>\n",
       "      <td>14.161261</td>\n",
       "      <td>51.884186</td>\n",
       "      <td>-4.201347</td>\n",
       "      <td>66.456535</td>\n",
       "      <td>9.085943</td>\n",
       "      <td>28.348587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 17:00:00</th>\n",
       "      <td>723.777489</td>\n",
       "      <td>564.278168</td>\n",
       "      <td>512.648949</td>\n",
       "      <td>369.877975</td>\n",
       "      <td>570.629890</td>\n",
       "      <td>610.507893</td>\n",
       "      <td>580.695488</td>\n",
       "      <td>620.765129</td>\n",
       "      <td>425.986862</td>\n",
       "      <td>418.322929</td>\n",
       "      <td>530.405319</td>\n",
       "      <td>417.365772</td>\n",
       "      <td>498.475746</td>\n",
       "      <td>329.886314</td>\n",
       "      <td>486.089482</td>\n",
       "      <td>355.270973</td>\n",
       "      <td>407.697708</td>\n",
       "      <td>251.040947</td>\n",
       "      <td>627.032145</td>\n",
       "      <td>324.631851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 18:00:00</th>\n",
       "      <td>601.239296</td>\n",
       "      <td>790.032784</td>\n",
       "      <td>537.203888</td>\n",
       "      <td>431.357143</td>\n",
       "      <td>501.388542</td>\n",
       "      <td>786.730129</td>\n",
       "      <td>623.974873</td>\n",
       "      <td>718.909050</td>\n",
       "      <td>475.328957</td>\n",
       "      <td>541.441115</td>\n",
       "      <td>551.275978</td>\n",
       "      <td>480.675771</td>\n",
       "      <td>582.550797</td>\n",
       "      <td>400.689995</td>\n",
       "      <td>435.502411</td>\n",
       "      <td>464.833977</td>\n",
       "      <td>384.023925</td>\n",
       "      <td>317.145485</td>\n",
       "      <td>581.076731</td>\n",
       "      <td>343.959616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 19:00:00</th>\n",
       "      <td>451.407333</td>\n",
       "      <td>677.496277</td>\n",
       "      <td>452.920929</td>\n",
       "      <td>476.786015</td>\n",
       "      <td>330.651260</td>\n",
       "      <td>643.647980</td>\n",
       "      <td>595.255699</td>\n",
       "      <td>550.101044</td>\n",
       "      <td>450.875908</td>\n",
       "      <td>489.310394</td>\n",
       "      <td>393.189049</td>\n",
       "      <td>467.148956</td>\n",
       "      <td>469.311478</td>\n",
       "      <td>379.301895</td>\n",
       "      <td>318.947479</td>\n",
       "      <td>476.809311</td>\n",
       "      <td>345.321648</td>\n",
       "      <td>307.922556</td>\n",
       "      <td>531.152332</td>\n",
       "      <td>294.941566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 20:00:00</th>\n",
       "      <td>387.020947</td>\n",
       "      <td>546.189560</td>\n",
       "      <td>574.797478</td>\n",
       "      <td>627.145325</td>\n",
       "      <td>278.109249</td>\n",
       "      <td>484.117748</td>\n",
       "      <td>504.923247</td>\n",
       "      <td>561.930832</td>\n",
       "      <td>568.960724</td>\n",
       "      <td>480.400444</td>\n",
       "      <td>471.288300</td>\n",
       "      <td>458.239399</td>\n",
       "      <td>328.748642</td>\n",
       "      <td>392.440029</td>\n",
       "      <td>301.312614</td>\n",
       "      <td>446.751053</td>\n",
       "      <td>312.372314</td>\n",
       "      <td>414.137123</td>\n",
       "      <td>502.949039</td>\n",
       "      <td>285.461412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 21:00:00</th>\n",
       "      <td>391.428429</td>\n",
       "      <td>533.443110</td>\n",
       "      <td>718.153824</td>\n",
       "      <td>738.425720</td>\n",
       "      <td>239.539066</td>\n",
       "      <td>390.523849</td>\n",
       "      <td>492.937976</td>\n",
       "      <td>511.917554</td>\n",
       "      <td>770.926788</td>\n",
       "      <td>457.537979</td>\n",
       "      <td>668.216934</td>\n",
       "      <td>415.723129</td>\n",
       "      <td>378.853790</td>\n",
       "      <td>424.154373</td>\n",
       "      <td>305.045279</td>\n",
       "      <td>424.800014</td>\n",
       "      <td>303.662302</td>\n",
       "      <td>484.507668</td>\n",
       "      <td>544.489288</td>\n",
       "      <td>271.019487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 22:00:00</th>\n",
       "      <td>267.075630</td>\n",
       "      <td>509.054070</td>\n",
       "      <td>770.715652</td>\n",
       "      <td>889.401947</td>\n",
       "      <td>179.807503</td>\n",
       "      <td>321.999401</td>\n",
       "      <td>476.219101</td>\n",
       "      <td>533.487610</td>\n",
       "      <td>735.408062</td>\n",
       "      <td>485.864418</td>\n",
       "      <td>476.129372</td>\n",
       "      <td>434.346190</td>\n",
       "      <td>367.449088</td>\n",
       "      <td>411.726379</td>\n",
       "      <td>279.640091</td>\n",
       "      <td>484.849289</td>\n",
       "      <td>256.466173</td>\n",
       "      <td>538.691458</td>\n",
       "      <td>461.846344</td>\n",
       "      <td>313.946955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29 23:00:00</th>\n",
       "      <td>150.937088</td>\n",
       "      <td>256.710144</td>\n",
       "      <td>506.912155</td>\n",
       "      <td>1070.869278</td>\n",
       "      <td>91.352810</td>\n",
       "      <td>256.723946</td>\n",
       "      <td>389.046707</td>\n",
       "      <td>459.318993</td>\n",
       "      <td>601.489914</td>\n",
       "      <td>400.981476</td>\n",
       "      <td>238.719269</td>\n",
       "      <td>416.989891</td>\n",
       "      <td>213.381416</td>\n",
       "      <td>412.793875</td>\n",
       "      <td>170.488037</td>\n",
       "      <td>487.248848</td>\n",
       "      <td>170.651131</td>\n",
       "      <td>532.204185</td>\n",
       "      <td>271.933426</td>\n",
       "      <td>275.776569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 00:00:00</th>\n",
       "      <td>62.725243</td>\n",
       "      <td>146.088699</td>\n",
       "      <td>311.975693</td>\n",
       "      <td>1186.355515</td>\n",
       "      <td>42.689209</td>\n",
       "      <td>132.719322</td>\n",
       "      <td>232.620766</td>\n",
       "      <td>338.039017</td>\n",
       "      <td>497.018356</td>\n",
       "      <td>233.554489</td>\n",
       "      <td>136.205132</td>\n",
       "      <td>296.282890</td>\n",
       "      <td>185.211159</td>\n",
       "      <td>415.104116</td>\n",
       "      <td>136.184624</td>\n",
       "      <td>350.496353</td>\n",
       "      <td>124.120193</td>\n",
       "      <td>638.722414</td>\n",
       "      <td>70.710365</td>\n",
       "      <td>242.281124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 01:00:00</th>\n",
       "      <td>56.443394</td>\n",
       "      <td>61.442688</td>\n",
       "      <td>243.255474</td>\n",
       "      <td>1078.388786</td>\n",
       "      <td>46.742037</td>\n",
       "      <td>81.871910</td>\n",
       "      <td>158.888329</td>\n",
       "      <td>233.498543</td>\n",
       "      <td>337.661324</td>\n",
       "      <td>187.987770</td>\n",
       "      <td>73.752754</td>\n",
       "      <td>233.144516</td>\n",
       "      <td>111.932308</td>\n",
       "      <td>386.532294</td>\n",
       "      <td>85.169498</td>\n",
       "      <td>273.185059</td>\n",
       "      <td>112.030785</td>\n",
       "      <td>410.034225</td>\n",
       "      <td>-14.947934</td>\n",
       "      <td>172.999453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 02:00:00</th>\n",
       "      <td>19.439938</td>\n",
       "      <td>16.078934</td>\n",
       "      <td>165.238873</td>\n",
       "      <td>707.695953</td>\n",
       "      <td>27.034667</td>\n",
       "      <td>74.787701</td>\n",
       "      <td>108.018486</td>\n",
       "      <td>179.205772</td>\n",
       "      <td>326.843830</td>\n",
       "      <td>119.101124</td>\n",
       "      <td>19.993778</td>\n",
       "      <td>129.223911</td>\n",
       "      <td>109.140318</td>\n",
       "      <td>307.460506</td>\n",
       "      <td>53.334997</td>\n",
       "      <td>198.381359</td>\n",
       "      <td>89.211367</td>\n",
       "      <td>289.427803</td>\n",
       "      <td>-11.893075</td>\n",
       "      <td>143.331173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 03:00:00</th>\n",
       "      <td>28.665546</td>\n",
       "      <td>17.320730</td>\n",
       "      <td>156.297702</td>\n",
       "      <td>389.383667</td>\n",
       "      <td>19.942121</td>\n",
       "      <td>57.014507</td>\n",
       "      <td>84.404968</td>\n",
       "      <td>106.644974</td>\n",
       "      <td>207.799042</td>\n",
       "      <td>114.983759</td>\n",
       "      <td>21.404314</td>\n",
       "      <td>118.029552</td>\n",
       "      <td>74.193356</td>\n",
       "      <td>191.187340</td>\n",
       "      <td>32.449158</td>\n",
       "      <td>159.438717</td>\n",
       "      <td>52.190910</td>\n",
       "      <td>187.837143</td>\n",
       "      <td>-9.580945</td>\n",
       "      <td>86.703854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 04:00:00</th>\n",
       "      <td>37.509821</td>\n",
       "      <td>17.496695</td>\n",
       "      <td>70.247536</td>\n",
       "      <td>115.584244</td>\n",
       "      <td>40.859205</td>\n",
       "      <td>35.047737</td>\n",
       "      <td>49.079486</td>\n",
       "      <td>37.374786</td>\n",
       "      <td>119.172401</td>\n",
       "      <td>96.424170</td>\n",
       "      <td>20.428072</td>\n",
       "      <td>58.267979</td>\n",
       "      <td>24.896606</td>\n",
       "      <td>89.592445</td>\n",
       "      <td>35.454053</td>\n",
       "      <td>107.370182</td>\n",
       "      <td>70.388788</td>\n",
       "      <td>52.852287</td>\n",
       "      <td>4.867274</td>\n",
       "      <td>44.567547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 05:00:00</th>\n",
       "      <td>70.819729</td>\n",
       "      <td>65.658928</td>\n",
       "      <td>72.109002</td>\n",
       "      <td>102.672920</td>\n",
       "      <td>82.162899</td>\n",
       "      <td>80.093784</td>\n",
       "      <td>93.257647</td>\n",
       "      <td>56.642536</td>\n",
       "      <td>174.087360</td>\n",
       "      <td>167.773155</td>\n",
       "      <td>54.483824</td>\n",
       "      <td>77.548866</td>\n",
       "      <td>59.245462</td>\n",
       "      <td>97.182907</td>\n",
       "      <td>67.267759</td>\n",
       "      <td>93.124674</td>\n",
       "      <td>74.121107</td>\n",
       "      <td>55.934667</td>\n",
       "      <td>24.197622</td>\n",
       "      <td>64.471847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 06:00:00</th>\n",
       "      <td>111.855713</td>\n",
       "      <td>94.654791</td>\n",
       "      <td>145.012829</td>\n",
       "      <td>127.243464</td>\n",
       "      <td>135.314346</td>\n",
       "      <td>144.982357</td>\n",
       "      <td>138.753075</td>\n",
       "      <td>85.785166</td>\n",
       "      <td>200.458266</td>\n",
       "      <td>234.484896</td>\n",
       "      <td>121.429111</td>\n",
       "      <td>139.714769</td>\n",
       "      <td>94.083687</td>\n",
       "      <td>113.865963</td>\n",
       "      <td>144.889763</td>\n",
       "      <td>86.402473</td>\n",
       "      <td>121.997478</td>\n",
       "      <td>76.874113</td>\n",
       "      <td>43.065205</td>\n",
       "      <td>80.052296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 07:00:00</th>\n",
       "      <td>175.550735</td>\n",
       "      <td>143.270641</td>\n",
       "      <td>238.324615</td>\n",
       "      <td>159.325806</td>\n",
       "      <td>233.534462</td>\n",
       "      <td>181.930431</td>\n",
       "      <td>221.588867</td>\n",
       "      <td>119.088375</td>\n",
       "      <td>273.739544</td>\n",
       "      <td>248.402401</td>\n",
       "      <td>233.097900</td>\n",
       "      <td>219.792938</td>\n",
       "      <td>138.140308</td>\n",
       "      <td>149.314941</td>\n",
       "      <td>236.792938</td>\n",
       "      <td>150.624653</td>\n",
       "      <td>223.419983</td>\n",
       "      <td>134.870346</td>\n",
       "      <td>110.424328</td>\n",
       "      <td>127.961720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 08:00:00</th>\n",
       "      <td>305.083961</td>\n",
       "      <td>267.996796</td>\n",
       "      <td>320.294655</td>\n",
       "      <td>236.054131</td>\n",
       "      <td>321.823158</td>\n",
       "      <td>284.609848</td>\n",
       "      <td>351.523247</td>\n",
       "      <td>244.261475</td>\n",
       "      <td>351.621136</td>\n",
       "      <td>332.308743</td>\n",
       "      <td>315.632553</td>\n",
       "      <td>309.042374</td>\n",
       "      <td>230.028175</td>\n",
       "      <td>198.839085</td>\n",
       "      <td>328.582542</td>\n",
       "      <td>196.903774</td>\n",
       "      <td>293.514275</td>\n",
       "      <td>182.351608</td>\n",
       "      <td>215.954441</td>\n",
       "      <td>199.028595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 09:00:00</th>\n",
       "      <td>392.718719</td>\n",
       "      <td>414.621742</td>\n",
       "      <td>453.130241</td>\n",
       "      <td>315.805916</td>\n",
       "      <td>430.207809</td>\n",
       "      <td>378.724121</td>\n",
       "      <td>439.114201</td>\n",
       "      <td>343.270981</td>\n",
       "      <td>443.046191</td>\n",
       "      <td>451.337906</td>\n",
       "      <td>403.637360</td>\n",
       "      <td>353.088942</td>\n",
       "      <td>327.110168</td>\n",
       "      <td>265.181755</td>\n",
       "      <td>398.255161</td>\n",
       "      <td>296.939774</td>\n",
       "      <td>350.447258</td>\n",
       "      <td>222.145587</td>\n",
       "      <td>329.767838</td>\n",
       "      <td>227.582560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 10:00:00</th>\n",
       "      <td>410.165863</td>\n",
       "      <td>400.280220</td>\n",
       "      <td>474.110432</td>\n",
       "      <td>303.558405</td>\n",
       "      <td>420.132889</td>\n",
       "      <td>423.668907</td>\n",
       "      <td>460.184494</td>\n",
       "      <td>375.493702</td>\n",
       "      <td>405.694452</td>\n",
       "      <td>585.028366</td>\n",
       "      <td>421.708847</td>\n",
       "      <td>377.337170</td>\n",
       "      <td>351.494694</td>\n",
       "      <td>298.260353</td>\n",
       "      <td>465.373459</td>\n",
       "      <td>329.449856</td>\n",
       "      <td>340.980610</td>\n",
       "      <td>228.351357</td>\n",
       "      <td>365.038934</td>\n",
       "      <td>282.125523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 11:00:00</th>\n",
       "      <td>473.580883</td>\n",
       "      <td>468.816277</td>\n",
       "      <td>427.510059</td>\n",
       "      <td>334.052254</td>\n",
       "      <td>511.372440</td>\n",
       "      <td>418.264160</td>\n",
       "      <td>439.277786</td>\n",
       "      <td>410.063118</td>\n",
       "      <td>412.037115</td>\n",
       "      <td>533.768379</td>\n",
       "      <td>457.968327</td>\n",
       "      <td>387.509869</td>\n",
       "      <td>368.611910</td>\n",
       "      <td>311.470692</td>\n",
       "      <td>481.901234</td>\n",
       "      <td>294.503366</td>\n",
       "      <td>371.901316</td>\n",
       "      <td>253.813486</td>\n",
       "      <td>307.555853</td>\n",
       "      <td>304.441645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 12:00:00</th>\n",
       "      <td>521.581543</td>\n",
       "      <td>491.544457</td>\n",
       "      <td>425.137372</td>\n",
       "      <td>373.421971</td>\n",
       "      <td>489.829665</td>\n",
       "      <td>422.361443</td>\n",
       "      <td>506.730907</td>\n",
       "      <td>445.783789</td>\n",
       "      <td>394.863251</td>\n",
       "      <td>520.148809</td>\n",
       "      <td>536.741357</td>\n",
       "      <td>380.625114</td>\n",
       "      <td>364.249537</td>\n",
       "      <td>312.895555</td>\n",
       "      <td>504.015874</td>\n",
       "      <td>313.759266</td>\n",
       "      <td>363.245992</td>\n",
       "      <td>255.926913</td>\n",
       "      <td>283.117865</td>\n",
       "      <td>288.659353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 13:00:00</th>\n",
       "      <td>536.564922</td>\n",
       "      <td>544.231216</td>\n",
       "      <td>432.719828</td>\n",
       "      <td>384.254425</td>\n",
       "      <td>457.201026</td>\n",
       "      <td>399.275072</td>\n",
       "      <td>495.787781</td>\n",
       "      <td>429.215924</td>\n",
       "      <td>381.596199</td>\n",
       "      <td>482.801605</td>\n",
       "      <td>462.853569</td>\n",
       "      <td>307.611954</td>\n",
       "      <td>373.151669</td>\n",
       "      <td>298.720308</td>\n",
       "      <td>484.462091</td>\n",
       "      <td>302.767126</td>\n",
       "      <td>346.545792</td>\n",
       "      <td>250.206007</td>\n",
       "      <td>268.734955</td>\n",
       "      <td>290.527700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 14:00:00</th>\n",
       "      <td>530.864983</td>\n",
       "      <td>545.382668</td>\n",
       "      <td>395.549641</td>\n",
       "      <td>349.144775</td>\n",
       "      <td>453.585402</td>\n",
       "      <td>365.714257</td>\n",
       "      <td>421.407068</td>\n",
       "      <td>453.237947</td>\n",
       "      <td>349.481598</td>\n",
       "      <td>463.783417</td>\n",
       "      <td>472.179600</td>\n",
       "      <td>299.938139</td>\n",
       "      <td>383.560903</td>\n",
       "      <td>318.829433</td>\n",
       "      <td>475.351670</td>\n",
       "      <td>329.795490</td>\n",
       "      <td>302.714010</td>\n",
       "      <td>266.461019</td>\n",
       "      <td>303.739079</td>\n",
       "      <td>294.907290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 15:00:00</th>\n",
       "      <td>558.721657</td>\n",
       "      <td>487.754329</td>\n",
       "      <td>478.592949</td>\n",
       "      <td>311.242165</td>\n",
       "      <td>447.626116</td>\n",
       "      <td>381.166317</td>\n",
       "      <td>350.865387</td>\n",
       "      <td>425.664185</td>\n",
       "      <td>385.750258</td>\n",
       "      <td>416.164707</td>\n",
       "      <td>525.900698</td>\n",
       "      <td>284.128433</td>\n",
       "      <td>390.381834</td>\n",
       "      <td>316.656839</td>\n",
       "      <td>478.081725</td>\n",
       "      <td>328.152304</td>\n",
       "      <td>291.855606</td>\n",
       "      <td>245.895847</td>\n",
       "      <td>286.627579</td>\n",
       "      <td>228.730534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 16:00:00</th>\n",
       "      <td>565.619585</td>\n",
       "      <td>557.653631</td>\n",
       "      <td>555.486105</td>\n",
       "      <td>408.544662</td>\n",
       "      <td>458.095837</td>\n",
       "      <td>435.876236</td>\n",
       "      <td>470.029022</td>\n",
       "      <td>496.561671</td>\n",
       "      <td>442.312197</td>\n",
       "      <td>473.492752</td>\n",
       "      <td>569.595119</td>\n",
       "      <td>341.118011</td>\n",
       "      <td>423.636948</td>\n",
       "      <td>355.081706</td>\n",
       "      <td>524.473315</td>\n",
       "      <td>312.290404</td>\n",
       "      <td>332.046227</td>\n",
       "      <td>273.039904</td>\n",
       "      <td>266.075273</td>\n",
       "      <td>299.524008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 17:00:00</th>\n",
       "      <td>528.857424</td>\n",
       "      <td>659.968712</td>\n",
       "      <td>570.037717</td>\n",
       "      <td>403.861977</td>\n",
       "      <td>419.903049</td>\n",
       "      <td>441.319420</td>\n",
       "      <td>474.946930</td>\n",
       "      <td>518.883087</td>\n",
       "      <td>550.022881</td>\n",
       "      <td>561.560146</td>\n",
       "      <td>549.453799</td>\n",
       "      <td>358.203413</td>\n",
       "      <td>431.340763</td>\n",
       "      <td>411.804901</td>\n",
       "      <td>493.396173</td>\n",
       "      <td>389.455032</td>\n",
       "      <td>344.990240</td>\n",
       "      <td>342.109955</td>\n",
       "      <td>281.300362</td>\n",
       "      <td>337.599842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 18:00:00</th>\n",
       "      <td>458.626221</td>\n",
       "      <td>578.531650</td>\n",
       "      <td>533.367189</td>\n",
       "      <td>428.497868</td>\n",
       "      <td>417.489918</td>\n",
       "      <td>467.931267</td>\n",
       "      <td>444.246494</td>\n",
       "      <td>456.664299</td>\n",
       "      <td>597.889060</td>\n",
       "      <td>544.216892</td>\n",
       "      <td>531.119024</td>\n",
       "      <td>376.500504</td>\n",
       "      <td>457.931114</td>\n",
       "      <td>435.277607</td>\n",
       "      <td>462.073830</td>\n",
       "      <td>372.250210</td>\n",
       "      <td>358.230860</td>\n",
       "      <td>379.648491</td>\n",
       "      <td>324.425310</td>\n",
       "      <td>321.301469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 19:00:00</th>\n",
       "      <td>309.474678</td>\n",
       "      <td>452.441223</td>\n",
       "      <td>474.916237</td>\n",
       "      <td>463.449286</td>\n",
       "      <td>281.141869</td>\n",
       "      <td>414.889519</td>\n",
       "      <td>399.772858</td>\n",
       "      <td>451.020958</td>\n",
       "      <td>461.014481</td>\n",
       "      <td>442.413200</td>\n",
       "      <td>427.473854</td>\n",
       "      <td>339.101120</td>\n",
       "      <td>368.273727</td>\n",
       "      <td>392.081522</td>\n",
       "      <td>343.573303</td>\n",
       "      <td>380.014545</td>\n",
       "      <td>291.960575</td>\n",
       "      <td>347.395961</td>\n",
       "      <td>214.697033</td>\n",
       "      <td>258.774843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 20:00:00</th>\n",
       "      <td>311.222721</td>\n",
       "      <td>394.093305</td>\n",
       "      <td>445.629597</td>\n",
       "      <td>534.306900</td>\n",
       "      <td>225.688614</td>\n",
       "      <td>321.146872</td>\n",
       "      <td>398.704163</td>\n",
       "      <td>448.331703</td>\n",
       "      <td>540.459442</td>\n",
       "      <td>444.381778</td>\n",
       "      <td>489.987259</td>\n",
       "      <td>331.010285</td>\n",
       "      <td>320.675319</td>\n",
       "      <td>388.162285</td>\n",
       "      <td>344.646296</td>\n",
       "      <td>335.972256</td>\n",
       "      <td>267.922028</td>\n",
       "      <td>403.364746</td>\n",
       "      <td>233.844082</td>\n",
       "      <td>246.050299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 21:00:00</th>\n",
       "      <td>271.564514</td>\n",
       "      <td>497.223511</td>\n",
       "      <td>822.285156</td>\n",
       "      <td>623.017296</td>\n",
       "      <td>181.338791</td>\n",
       "      <td>319.856654</td>\n",
       "      <td>396.007280</td>\n",
       "      <td>503.736092</td>\n",
       "      <td>762.628052</td>\n",
       "      <td>491.399612</td>\n",
       "      <td>575.260635</td>\n",
       "      <td>376.400341</td>\n",
       "      <td>346.293198</td>\n",
       "      <td>389.288906</td>\n",
       "      <td>336.649296</td>\n",
       "      <td>383.401539</td>\n",
       "      <td>261.502438</td>\n",
       "      <td>486.828911</td>\n",
       "      <td>253.813679</td>\n",
       "      <td>286.190748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30 22:00:00</th>\n",
       "      <td>211.083191</td>\n",
       "      <td>530.448593</td>\n",
       "      <td>751.880035</td>\n",
       "      <td>747.766388</td>\n",
       "      <td>133.467022</td>\n",
       "      <td>304.029423</td>\n",
       "      <td>398.618328</td>\n",
       "      <td>506.804401</td>\n",
       "      <td>672.462881</td>\n",
       "      <td>440.806585</td>\n",
       "      <td>531.282166</td>\n",
       "      <td>381.024582</td>\n",
       "      <td>277.693763</td>\n",
       "      <td>388.478218</td>\n",
       "      <td>216.722572</td>\n",
       "      <td>437.683685</td>\n",
       "      <td>206.208920</td>\n",
       "      <td>527.958389</td>\n",
       "      <td>144.950447</td>\n",
       "      <td>267.468649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65711 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            237         161         230           79  \\\n",
       "date                                                                   \n",
       "2011-01-01 00:00:00  378.765518  357.815909  170.954948  1169.934412   \n",
       "2011-01-01 01:00:00  181.884430  168.474030   42.926036   622.392572   \n",
       "2011-01-01 02:00:00  241.671692   96.039963   29.937252   584.864774   \n",
       "2011-01-01 03:00:00  189.511894  167.290459   10.560440   472.070137   \n",
       "2011-01-01 04:00:00  110.338257  136.352837   83.788517   416.465500   \n",
       "2011-01-01 05:00:00   62.164257   54.906208   89.495232   259.148331   \n",
       "2011-01-01 06:00:00   66.781725   61.357931  134.885628   295.728729   \n",
       "2011-01-01 07:00:00   84.726795   67.493668  153.786304   298.408325   \n",
       "2011-01-01 08:00:00  101.432892  100.571232  163.821236   195.815018   \n",
       "2011-01-01 09:00:00  121.160362  116.529305  163.194427   195.470207   \n",
       "2011-01-01 10:00:00  210.421906  211.488251  221.520355   235.293434   \n",
       "2011-01-01 11:00:00  264.718620  278.072281  260.599747   214.679779   \n",
       "2011-01-01 12:00:00  315.979485  285.259010  299.419006   250.709694   \n",
       "2011-01-01 13:00:00  366.979446  329.070679  287.340218   301.168571   \n",
       "2011-01-01 14:00:00  350.638176  384.496162  300.278076   327.490860   \n",
       "2011-01-01 15:00:00  381.791397  358.231575  268.366526   314.510120   \n",
       "2011-01-01 16:00:00  326.586740  308.809441  327.177530   290.440400   \n",
       "2011-01-01 17:00:00  341.422798  322.741219  280.993858   352.455864   \n",
       "2011-01-01 18:00:00  341.244053  306.845074  316.409527   429.343079   \n",
       "2011-01-01 19:00:00  264.393866  336.588946  316.067490   502.199432   \n",
       "2011-01-01 20:00:00  267.187412  301.472530  231.311813   493.253799   \n",
       "2011-01-01 21:00:00  141.130562  220.736111  244.526550   413.584549   \n",
       "2011-01-01 22:00:00  125.368629  179.892929  334.013485   424.138651   \n",
       "2011-01-01 23:00:00  131.661415  105.858391  437.885292   436.778999   \n",
       "2011-01-02 00:00:00   55.905266  105.983238  300.193527   367.743668   \n",
       "2011-01-02 01:00:00   45.921829   46.107986  281.299320   502.949783   \n",
       "2011-01-02 02:00:00   11.945354   12.450943  222.016727   663.796368   \n",
       "2011-01-02 03:00:00  -16.884789  -22.616383  121.308712   697.478157   \n",
       "2011-01-02 04:00:00  -19.448544   -8.468880   99.458595   338.882568   \n",
       "2011-01-02 05:00:00    6.229615   -2.304180   52.110916   184.504532   \n",
       "...                         ...         ...         ...          ...   \n",
       "2018-06-29 17:00:00  723.777489  564.278168  512.648949   369.877975   \n",
       "2018-06-29 18:00:00  601.239296  790.032784  537.203888   431.357143   \n",
       "2018-06-29 19:00:00  451.407333  677.496277  452.920929   476.786015   \n",
       "2018-06-29 20:00:00  387.020947  546.189560  574.797478   627.145325   \n",
       "2018-06-29 21:00:00  391.428429  533.443110  718.153824   738.425720   \n",
       "2018-06-29 22:00:00  267.075630  509.054070  770.715652   889.401947   \n",
       "2018-06-29 23:00:00  150.937088  256.710144  506.912155  1070.869278   \n",
       "2018-06-30 00:00:00   62.725243  146.088699  311.975693  1186.355515   \n",
       "2018-06-30 01:00:00   56.443394   61.442688  243.255474  1078.388786   \n",
       "2018-06-30 02:00:00   19.439938   16.078934  165.238873   707.695953   \n",
       "2018-06-30 03:00:00   28.665546   17.320730  156.297702   389.383667   \n",
       "2018-06-30 04:00:00   37.509821   17.496695   70.247536   115.584244   \n",
       "2018-06-30 05:00:00   70.819729   65.658928   72.109002   102.672920   \n",
       "2018-06-30 06:00:00  111.855713   94.654791  145.012829   127.243464   \n",
       "2018-06-30 07:00:00  175.550735  143.270641  238.324615   159.325806   \n",
       "2018-06-30 08:00:00  305.083961  267.996796  320.294655   236.054131   \n",
       "2018-06-30 09:00:00  392.718719  414.621742  453.130241   315.805916   \n",
       "2018-06-30 10:00:00  410.165863  400.280220  474.110432   303.558405   \n",
       "2018-06-30 11:00:00  473.580883  468.816277  427.510059   334.052254   \n",
       "2018-06-30 12:00:00  521.581543  491.544457  425.137372   373.421971   \n",
       "2018-06-30 13:00:00  536.564922  544.231216  432.719828   384.254425   \n",
       "2018-06-30 14:00:00  530.864983  545.382668  395.549641   349.144775   \n",
       "2018-06-30 15:00:00  558.721657  487.754329  478.592949   311.242165   \n",
       "2018-06-30 16:00:00  565.619585  557.653631  555.486105   408.544662   \n",
       "2018-06-30 17:00:00  528.857424  659.968712  570.037717   403.861977   \n",
       "2018-06-30 18:00:00  458.626221  578.531650  533.367189   428.497868   \n",
       "2018-06-30 19:00:00  309.474678  452.441223  474.916237   463.449286   \n",
       "2018-06-30 20:00:00  311.222721  394.093305  445.629597   534.306900   \n",
       "2018-06-30 21:00:00  271.564514  497.223511  822.285156   623.017296   \n",
       "2018-06-30 22:00:00  211.083191  530.448593  751.880035   747.766388   \n",
       "\n",
       "                            236         162         170         234  \\\n",
       "date                                                                  \n",
       "2011-01-01 00:00:00  442.598282  377.660637  550.033426  629.927204   \n",
       "2011-01-01 01:00:00  233.041191  168.738678  419.629261  424.060136   \n",
       "2011-01-01 02:00:00  250.420319  212.491394  414.283463  259.114410   \n",
       "2011-01-01 03:00:00  229.376633  216.780785  359.250160  144.219376   \n",
       "2011-01-01 04:00:00  116.343174  176.087357  271.892715  120.585670   \n",
       "2011-01-01 05:00:00   61.549626  110.638420  148.955566   99.215950   \n",
       "2011-01-01 06:00:00   87.218090   70.971793  112.930840  100.278843   \n",
       "2011-01-01 07:00:00   82.917557   86.868332  103.207989  100.012419   \n",
       "2011-01-01 08:00:00  127.228683   88.336998  128.774742  111.582752   \n",
       "2011-01-01 09:00:00  143.858780  121.915550  144.180702  122.628166   \n",
       "2011-01-01 10:00:00  212.556702  195.916382  218.488708  146.403275   \n",
       "2011-01-01 11:00:00  240.494743  246.029572  277.038132  173.997864   \n",
       "2011-01-01 12:00:00  315.425308  303.454735  328.073013  236.796822   \n",
       "2011-01-01 13:00:00  328.584091  310.146729  346.519516  277.514160   \n",
       "2011-01-01 14:00:00  326.107101  315.935982  314.594063  281.650734   \n",
       "2011-01-01 15:00:00  286.985786  297.677433  305.386459  270.785347   \n",
       "2011-01-01 16:00:00  289.070103  221.213147  297.489481  238.097770   \n",
       "2011-01-01 17:00:00  316.241249  247.207329  299.675949  264.049000   \n",
       "2011-01-01 18:00:00  301.216553  293.618177  358.656837  284.166855   \n",
       "2011-01-01 19:00:00  309.611843  268.336823  406.879822  313.281395   \n",
       "2011-01-01 20:00:00  290.896090  293.721948  414.278152  262.071064   \n",
       "2011-01-01 21:00:00  215.725537  202.197065  290.414399  223.754000   \n",
       "2011-01-01 22:00:00  181.149927  154.370926  197.302109  181.868769   \n",
       "2011-01-01 23:00:00  166.974571   99.741211  194.532898  217.459042   \n",
       "2011-01-02 00:00:00   77.498795   86.031029  209.765381  138.712593   \n",
       "2011-01-02 01:00:00   47.472668   90.936802  167.901207  198.260700   \n",
       "2011-01-02 02:00:00   19.233143   30.605087  131.117233  131.352795   \n",
       "2011-01-02 03:00:00   -5.059177   14.348747  122.727448   96.253059   \n",
       "2011-01-02 04:00:00   -9.391819   -2.070023   50.616608   63.739723   \n",
       "2011-01-02 05:00:00   -7.107853    1.122986    4.986832    8.479103   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-06-29 17:00:00  570.629890  610.507893  580.695488  620.765129   \n",
       "2018-06-29 18:00:00  501.388542  786.730129  623.974873  718.909050   \n",
       "2018-06-29 19:00:00  330.651260  643.647980  595.255699  550.101044   \n",
       "2018-06-29 20:00:00  278.109249  484.117748  504.923247  561.930832   \n",
       "2018-06-29 21:00:00  239.539066  390.523849  492.937976  511.917554   \n",
       "2018-06-29 22:00:00  179.807503  321.999401  476.219101  533.487610   \n",
       "2018-06-29 23:00:00   91.352810  256.723946  389.046707  459.318993   \n",
       "2018-06-30 00:00:00   42.689209  132.719322  232.620766  338.039017   \n",
       "2018-06-30 01:00:00   46.742037   81.871910  158.888329  233.498543   \n",
       "2018-06-30 02:00:00   27.034667   74.787701  108.018486  179.205772   \n",
       "2018-06-30 03:00:00   19.942121   57.014507   84.404968  106.644974   \n",
       "2018-06-30 04:00:00   40.859205   35.047737   49.079486   37.374786   \n",
       "2018-06-30 05:00:00   82.162899   80.093784   93.257647   56.642536   \n",
       "2018-06-30 06:00:00  135.314346  144.982357  138.753075   85.785166   \n",
       "2018-06-30 07:00:00  233.534462  181.930431  221.588867  119.088375   \n",
       "2018-06-30 08:00:00  321.823158  284.609848  351.523247  244.261475   \n",
       "2018-06-30 09:00:00  430.207809  378.724121  439.114201  343.270981   \n",
       "2018-06-30 10:00:00  420.132889  423.668907  460.184494  375.493702   \n",
       "2018-06-30 11:00:00  511.372440  418.264160  439.277786  410.063118   \n",
       "2018-06-30 12:00:00  489.829665  422.361443  506.730907  445.783789   \n",
       "2018-06-30 13:00:00  457.201026  399.275072  495.787781  429.215924   \n",
       "2018-06-30 14:00:00  453.585402  365.714257  421.407068  453.237947   \n",
       "2018-06-30 15:00:00  447.626116  381.166317  350.865387  425.664185   \n",
       "2018-06-30 16:00:00  458.095837  435.876236  470.029022  496.561671   \n",
       "2018-06-30 17:00:00  419.903049  441.319420  474.946930  518.883087   \n",
       "2018-06-30 18:00:00  417.489918  467.931267  444.246494  456.664299   \n",
       "2018-06-30 19:00:00  281.141869  414.889519  399.772858  451.020958   \n",
       "2018-06-30 20:00:00  225.688614  321.146872  398.704163  448.331703   \n",
       "2018-06-30 21:00:00  181.338791  319.856654  396.007280  503.736092   \n",
       "2018-06-30 22:00:00  133.467022  304.029423  398.618328  506.804401   \n",
       "\n",
       "                             48         186         142         107  \\\n",
       "date                                                                  \n",
       "2011-01-01 00:00:00  595.273397  309.469646  471.259277  729.279806   \n",
       "2011-01-01 01:00:00  353.670305  125.292004  222.339844  448.033763   \n",
       "2011-01-01 02:00:00  279.256687  142.871590  193.208305  429.281321   \n",
       "2011-01-01 03:00:00  231.996140  101.239594  164.243835  317.994476   \n",
       "2011-01-01 04:00:00  314.153542  150.121731  152.050491  315.191330   \n",
       "2011-01-01 05:00:00  213.046333   97.153419   82.878651  241.789742   \n",
       "2011-01-01 06:00:00  231.373892  102.563267   88.324356  113.528565   \n",
       "2011-01-01 07:00:00  156.731279  110.103443   75.645695  121.926693   \n",
       "2011-01-01 08:00:00  175.556850  121.871658  107.839367  123.028694   \n",
       "2011-01-01 09:00:00  198.226601  129.227875  165.387985  117.207775   \n",
       "2011-01-01 10:00:00  232.650986  183.310333  189.803505  174.052467   \n",
       "2011-01-01 11:00:00  201.748627  253.915451  226.565849  202.942123   \n",
       "2011-01-01 12:00:00  266.555565  224.831696  263.467003  263.059372   \n",
       "2011-01-01 13:00:00  297.950352  259.552557  334.078354  273.790970   \n",
       "2011-01-01 14:00:00  293.062885  335.799675  324.501717  290.459682   \n",
       "2011-01-01 15:00:00  237.995687  258.674180  350.943344  250.369785   \n",
       "2011-01-01 16:00:00  247.380360  207.261833  304.320062  253.149476   \n",
       "2011-01-01 17:00:00  270.605270  253.063534  317.771507  244.479557   \n",
       "2011-01-01 18:00:00  352.777855  329.982674  393.319580  320.056221   \n",
       "2011-01-01 19:00:00  354.474747  350.384815  400.514313  336.833344   \n",
       "2011-01-01 20:00:00  367.300785  309.378915  310.984436  375.702324   \n",
       "2011-01-01 21:00:00  295.448334  279.255835  317.672386  285.174797   \n",
       "2011-01-01 22:00:00  410.831909  208.201893  327.136047  224.946512   \n",
       "2011-01-01 23:00:00  351.388763  207.140076  343.861663  268.505022   \n",
       "2011-01-02 00:00:00  251.548210  258.077316  194.236282  189.756264   \n",
       "2011-01-02 01:00:00  332.514687  232.868706  146.092514  295.379374   \n",
       "2011-01-02 02:00:00  244.937813  128.369022   55.573326  170.616825   \n",
       "2011-01-02 03:00:00  183.537323   73.166492   32.011642   93.591557   \n",
       "2011-01-02 04:00:00  144.440643   14.333855   13.443787   57.648178   \n",
       "2011-01-02 05:00:00   95.472557   35.724979  -19.261410    6.922081   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-06-29 17:00:00  425.986862  418.322929  530.405319  417.365772   \n",
       "2018-06-29 18:00:00  475.328957  541.441115  551.275978  480.675771   \n",
       "2018-06-29 19:00:00  450.875908  489.310394  393.189049  467.148956   \n",
       "2018-06-29 20:00:00  568.960724  480.400444  471.288300  458.239399   \n",
       "2018-06-29 21:00:00  770.926788  457.537979  668.216934  415.723129   \n",
       "2018-06-29 22:00:00  735.408062  485.864418  476.129372  434.346190   \n",
       "2018-06-29 23:00:00  601.489914  400.981476  238.719269  416.989891   \n",
       "2018-06-30 00:00:00  497.018356  233.554489  136.205132  296.282890   \n",
       "2018-06-30 01:00:00  337.661324  187.987770   73.752754  233.144516   \n",
       "2018-06-30 02:00:00  326.843830  119.101124   19.993778  129.223911   \n",
       "2018-06-30 03:00:00  207.799042  114.983759   21.404314  118.029552   \n",
       "2018-06-30 04:00:00  119.172401   96.424170   20.428072   58.267979   \n",
       "2018-06-30 05:00:00  174.087360  167.773155   54.483824   77.548866   \n",
       "2018-06-30 06:00:00  200.458266  234.484896  121.429111  139.714769   \n",
       "2018-06-30 07:00:00  273.739544  248.402401  233.097900  219.792938   \n",
       "2018-06-30 08:00:00  351.621136  332.308743  315.632553  309.042374   \n",
       "2018-06-30 09:00:00  443.046191  451.337906  403.637360  353.088942   \n",
       "2018-06-30 10:00:00  405.694452  585.028366  421.708847  377.337170   \n",
       "2018-06-30 11:00:00  412.037115  533.768379  457.968327  387.509869   \n",
       "2018-06-30 12:00:00  394.863251  520.148809  536.741357  380.625114   \n",
       "2018-06-30 13:00:00  381.596199  482.801605  462.853569  307.611954   \n",
       "2018-06-30 14:00:00  349.481598  463.783417  472.179600  299.938139   \n",
       "2018-06-30 15:00:00  385.750258  416.164707  525.900698  284.128433   \n",
       "2018-06-30 16:00:00  442.312197  473.492752  569.595119  341.118011   \n",
       "2018-06-30 17:00:00  550.022881  561.560146  549.453799  358.203413   \n",
       "2018-06-30 18:00:00  597.889060  544.216892  531.119024  376.500504   \n",
       "2018-06-30 19:00:00  461.014481  442.413200  427.473854  339.101120   \n",
       "2018-06-30 20:00:00  540.459442  444.381778  489.987259  331.010285   \n",
       "2018-06-30 21:00:00  762.628052  491.399612  575.260635  376.400341   \n",
       "2018-06-30 22:00:00  672.462881  440.806585  531.282166  381.024582   \n",
       "\n",
       "                            163          68         239         164  \\\n",
       "date                                                                  \n",
       "2011-01-01 00:00:00  207.935535  590.287590  428.227081  418.747496   \n",
       "2011-01-01 01:00:00  106.633280  385.276383  219.484436  272.536284   \n",
       "2011-01-01 02:00:00   89.379490  309.107438  298.728119  264.542053   \n",
       "2011-01-01 03:00:00  102.161911  305.833828  284.499657  174.675640   \n",
       "2011-01-01 04:00:00  107.946434  203.333633  174.203522  194.469173   \n",
       "2011-01-01 05:00:00   43.310005  122.863838  110.274092  141.823845   \n",
       "2011-01-01 06:00:00   73.603363   72.584560   72.351177  123.736671   \n",
       "2011-01-01 07:00:00   78.401155  132.896870   85.122429  102.120327   \n",
       "2011-01-01 08:00:00   80.145538  124.796234  110.470451   99.240084   \n",
       "2011-01-01 09:00:00   80.417599  125.327011  161.142014   90.730434   \n",
       "2011-01-01 10:00:00  180.632423  138.809082  206.041893  149.250412   \n",
       "2011-01-01 11:00:00  210.748589  181.676880  228.131721  173.112328   \n",
       "2011-01-01 12:00:00  223.240524  211.865387  329.763794  222.750519   \n",
       "2011-01-01 13:00:00  264.771416  241.050468  334.310555  233.139618   \n",
       "2011-01-01 14:00:00  313.129333  217.709747  292.675247  233.829376   \n",
       "2011-01-01 15:00:00  267.460201  206.399977  311.282410  214.228155   \n",
       "2011-01-01 16:00:00  223.537010  164.221707  291.681856  190.436602   \n",
       "2011-01-01 17:00:00  215.321370  181.392365  285.166294  193.945667   \n",
       "2011-01-01 18:00:00  222.804876  200.562378  311.303169  230.925793   \n",
       "2011-01-01 19:00:00  258.476542  283.561913  258.430707  265.027691   \n",
       "2011-01-01 20:00:00  203.714256  277.583893  228.946226  253.911221   \n",
       "2011-01-01 21:00:00  132.177114  221.120461  196.698016  204.624383   \n",
       "2011-01-01 22:00:00  156.130494  163.188511  155.358354  199.868029   \n",
       "2011-01-01 23:00:00  134.945267  176.980647  178.351964  185.561311   \n",
       "2011-01-02 00:00:00  103.759190  165.800964  100.871819  208.461800   \n",
       "2011-01-02 01:00:00   85.384705  222.072850   97.493496  242.553616   \n",
       "2011-01-02 02:00:00   67.268383  191.427484   80.006527  190.963463   \n",
       "2011-01-02 03:00:00   51.762394   88.442436   64.470215  118.349018   \n",
       "2011-01-02 04:00:00   45.203697   89.829311    5.117950   68.114414   \n",
       "2011-01-02 05:00:00   15.805103   53.903572   14.161261   51.884186   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-06-29 17:00:00  498.475746  329.886314  486.089482  355.270973   \n",
       "2018-06-29 18:00:00  582.550797  400.689995  435.502411  464.833977   \n",
       "2018-06-29 19:00:00  469.311478  379.301895  318.947479  476.809311   \n",
       "2018-06-29 20:00:00  328.748642  392.440029  301.312614  446.751053   \n",
       "2018-06-29 21:00:00  378.853790  424.154373  305.045279  424.800014   \n",
       "2018-06-29 22:00:00  367.449088  411.726379  279.640091  484.849289   \n",
       "2018-06-29 23:00:00  213.381416  412.793875  170.488037  487.248848   \n",
       "2018-06-30 00:00:00  185.211159  415.104116  136.184624  350.496353   \n",
       "2018-06-30 01:00:00  111.932308  386.532294   85.169498  273.185059   \n",
       "2018-06-30 02:00:00  109.140318  307.460506   53.334997  198.381359   \n",
       "2018-06-30 03:00:00   74.193356  191.187340   32.449158  159.438717   \n",
       "2018-06-30 04:00:00   24.896606   89.592445   35.454053  107.370182   \n",
       "2018-06-30 05:00:00   59.245462   97.182907   67.267759   93.124674   \n",
       "2018-06-30 06:00:00   94.083687  113.865963  144.889763   86.402473   \n",
       "2018-06-30 07:00:00  138.140308  149.314941  236.792938  150.624653   \n",
       "2018-06-30 08:00:00  230.028175  198.839085  328.582542  196.903774   \n",
       "2018-06-30 09:00:00  327.110168  265.181755  398.255161  296.939774   \n",
       "2018-06-30 10:00:00  351.494694  298.260353  465.373459  329.449856   \n",
       "2018-06-30 11:00:00  368.611910  311.470692  481.901234  294.503366   \n",
       "2018-06-30 12:00:00  364.249537  312.895555  504.015874  313.759266   \n",
       "2018-06-30 13:00:00  373.151669  298.720308  484.462091  302.767126   \n",
       "2018-06-30 14:00:00  383.560903  318.829433  475.351670  329.795490   \n",
       "2018-06-30 15:00:00  390.381834  316.656839  478.081725  328.152304   \n",
       "2018-06-30 16:00:00  423.636948  355.081706  524.473315  312.290404   \n",
       "2018-06-30 17:00:00  431.340763  411.804901  493.396173  389.455032   \n",
       "2018-06-30 18:00:00  457.931114  435.277607  462.073830  372.250210   \n",
       "2018-06-30 19:00:00  368.273727  392.081522  343.573303  380.014545   \n",
       "2018-06-30 20:00:00  320.675319  388.162285  344.646296  335.972256   \n",
       "2018-06-30 21:00:00  346.293198  389.288906  336.649296  383.401539   \n",
       "2018-06-30 22:00:00  277.693763  388.478218  216.722572  437.683685   \n",
       "\n",
       "                            141         249         138          90  \n",
       "date                                                                 \n",
       "2011-01-01 00:00:00  397.209515  592.011109  253.741570  465.114122  \n",
       "2011-01-01 01:00:00  282.326519  351.437659   17.621679  298.460461  \n",
       "2011-01-01 02:00:00  345.457260  247.204753  -33.437027  207.911047  \n",
       "2011-01-01 03:00:00  280.474159  220.177378    4.844269  167.948177  \n",
       "2011-01-01 04:00:00  225.335232  149.999481    7.342397  201.800657  \n",
       "2011-01-01 05:00:00  125.010246  128.085880    7.036086  144.025841  \n",
       "2011-01-01 06:00:00   89.766273  121.528501   17.609750   94.061470  \n",
       "2011-01-01 07:00:00   71.124947  133.895611   40.226765  123.242514  \n",
       "2011-01-01 08:00:00  119.437119   89.794327   78.869400   92.342709  \n",
       "2011-01-01 09:00:00  115.199486   94.248634  119.996246   96.119381  \n",
       "2011-01-01 10:00:00  173.798149  118.917366  189.833778  116.565098  \n",
       "2011-01-01 11:00:00  222.232376  161.172516  175.700504  150.635780  \n",
       "2011-01-01 12:00:00  253.387436  188.683861  208.724850  195.445396  \n",
       "2011-01-01 13:00:00  280.883537  193.336258  204.551811  223.744759  \n",
       "2011-01-01 14:00:00  249.666718  210.617985  181.458952  211.402687  \n",
       "2011-01-01 15:00:00  277.571480  219.789581  152.124468  192.987309  \n",
       "2011-01-01 16:00:00  255.695534  182.498240  193.556034  154.980534  \n",
       "2011-01-01 17:00:00  320.420021  217.987247  184.766660  196.200218  \n",
       "2011-01-01 18:00:00  323.323357  234.247375  197.124294  216.825577  \n",
       "2011-01-01 19:00:00  325.846344  322.735542  216.265659  249.125923  \n",
       "2011-01-01 20:00:00  284.669092  305.266815  122.268333  255.431992  \n",
       "2011-01-01 21:00:00  222.191813  273.912674  143.210379  187.391262  \n",
       "2011-01-01 22:00:00  185.462097  210.804609  194.105114  169.690871  \n",
       "2011-01-01 23:00:00  179.072845  229.096519  123.822205  141.373773  \n",
       "2011-01-02 00:00:00  115.800812  209.518257  120.369370  116.192848  \n",
       "2011-01-02 01:00:00  109.241611  253.544197   60.478054  131.872013  \n",
       "2011-01-02 02:00:00   54.370148  298.169636    4.517738   98.029636  \n",
       "2011-01-02 03:00:00   31.011280  199.042923   25.637240  103.248489  \n",
       "2011-01-02 04:00:00   31.671753   97.615257    1.826038   61.033833  \n",
       "2011-01-02 05:00:00   -4.201347   66.456535    9.085943   28.348587  \n",
       "...                         ...         ...         ...         ...  \n",
       "2018-06-29 17:00:00  407.697708  251.040947  627.032145  324.631851  \n",
       "2018-06-29 18:00:00  384.023925  317.145485  581.076731  343.959616  \n",
       "2018-06-29 19:00:00  345.321648  307.922556  531.152332  294.941566  \n",
       "2018-06-29 20:00:00  312.372314  414.137123  502.949039  285.461412  \n",
       "2018-06-29 21:00:00  303.662302  484.507668  544.489288  271.019487  \n",
       "2018-06-29 22:00:00  256.466173  538.691458  461.846344  313.946955  \n",
       "2018-06-29 23:00:00  170.651131  532.204185  271.933426  275.776569  \n",
       "2018-06-30 00:00:00  124.120193  638.722414   70.710365  242.281124  \n",
       "2018-06-30 01:00:00  112.030785  410.034225  -14.947934  172.999453  \n",
       "2018-06-30 02:00:00   89.211367  289.427803  -11.893075  143.331173  \n",
       "2018-06-30 03:00:00   52.190910  187.837143   -9.580945   86.703854  \n",
       "2018-06-30 04:00:00   70.388788   52.852287    4.867274   44.567547  \n",
       "2018-06-30 05:00:00   74.121107   55.934667   24.197622   64.471847  \n",
       "2018-06-30 06:00:00  121.997478   76.874113   43.065205   80.052296  \n",
       "2018-06-30 07:00:00  223.419983  134.870346  110.424328  127.961720  \n",
       "2018-06-30 08:00:00  293.514275  182.351608  215.954441  199.028595  \n",
       "2018-06-30 09:00:00  350.447258  222.145587  329.767838  227.582560  \n",
       "2018-06-30 10:00:00  340.980610  228.351357  365.038934  282.125523  \n",
       "2018-06-30 11:00:00  371.901316  253.813486  307.555853  304.441645  \n",
       "2018-06-30 12:00:00  363.245992  255.926913  283.117865  288.659353  \n",
       "2018-06-30 13:00:00  346.545792  250.206007  268.734955  290.527700  \n",
       "2018-06-30 14:00:00  302.714010  266.461019  303.739079  294.907290  \n",
       "2018-06-30 15:00:00  291.855606  245.895847  286.627579  228.730534  \n",
       "2018-06-30 16:00:00  332.046227  273.039904  266.075273  299.524008  \n",
       "2018-06-30 17:00:00  344.990240  342.109955  281.300362  337.599842  \n",
       "2018-06-30 18:00:00  358.230860  379.648491  324.425310  321.301469  \n",
       "2018-06-30 19:00:00  291.960575  347.395961  214.697033  258.774843  \n",
       "2018-06-30 20:00:00  267.922028  403.364746  233.844082  246.050299  \n",
       "2018-06-30 21:00:00  261.502438  486.828911  253.813679  286.190748  \n",
       "2018-06-30 22:00:00  206.208920  527.958389  144.950447  267.468649  \n",
       "\n",
       "[65711 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store models & history on disk:\n",
    "\n",
    "model_save_PATH = '/media/...'\n",
    "df_save_PATH = '/media/...'\n",
    "\n",
    "#call function to store models & history on disk:\n",
    "_ = sv_files.store_model_and_history_on_disk(all_cplxMLP_MODELS_dict_retrain, model_save_PATH, df_save_PATH)\n",
    "\n",
    "#call function to store prediction results:\n",
    "_ = sv_files.store_retrained_predictions(all_cplxMLP_RESULTS_dict_retrain, all_cplxMLP_MODELS_dict_retrain, df_save_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy: Incremental training / updating of model on a quarterly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:23:43.668071Z",
     "start_time": "2020-01-23T13:21:50.607249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting based on given months is used...\n",
      "Shifting Window based on given months is used:  3\n",
      "Retraining range based on years:  2\n",
      "## Very first predictions with given pre-defined model are made..\n",
      "months to predict:  3\n",
      "## Assigned Dates are double checked..\n",
      "selected years for training:  ['2009', Timestamp('2010-12-31 23:00:00')]\n",
      "year_list given:  ['2009', Timestamp('2010-12-31 23:00:00'), '2011-01-01 00:00:00', None]\n",
      "#### Make predictions model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_update_weights_quarterly ####\n",
      "43200/43200 [==============================] - 1s 26us/step\n",
      "Shape of org. dataset after shift:  (2160, 20)\n",
      "20/20 [==============================] - 0s 43us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## Avg. RMSE of recent predictions: \n",
      "[65.07505260778235]\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:22:02\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-04-01 00:00:00'), Timestamp('2011-03-31 23:00:00'), Timestamp('2011-04-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_update_weights_quarterly__trainsize729_s4_2009_e3_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "## Existing Model is updated..\n",
      "#Clipping Norm applied\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2081 - mean_absolute_error: 0.3277\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 4s 13us/step - loss: 0.2070 - mean_absolute_error: 0.3269\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2061 - mean_absolute_error: 0.3264\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2057 - mean_absolute_error: 0.3258\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2051 - mean_absolute_error: 0.3258\n",
      "43680/43680 [==============================] - 1s 27us/step\n",
      "Shape of org. dataset after shift:  (2184, 20)\n",
      "20/20 [==============================] - 0s 45us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## Avg. RMSE of recent predictions: \n",
      "[59.963794605908404]\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:22:36\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-07-01 00:00:00'), Timestamp('2011-06-30 23:00:00'), Timestamp('2011-07-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_update_weights_quarterly__trainsize729_s7_2009_e6_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "## Existing Model is updated..\n",
      "#Clipping Norm applied\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2049 - mean_absolute_error: 0.3260\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2040 - mean_absolute_error: 0.3254\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2036 - mean_absolute_error: 0.3249\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2036 - mean_absolute_error: 0.3251\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2029 - mean_absolute_error: 0.3245\n",
      "44160/44160 [==============================] - 1s 30us/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "20/20 [==============================] - 0s 44us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## Avg. RMSE of recent predictions: \n",
      "[60.43247531469768]\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:23:10\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00')]\n",
      "year_list given:  [Timestamp('2009-10-01 00:00:00'), Timestamp('2011-09-30 23:00:00'), Timestamp('2011-10-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_update_weights_quarterly__trainsize729_s10_2009_e9_2011__stepsize1__p12_2011 ####\n",
      "Keras Model is used...\n",
      "## Existing Model is updated..\n",
      "#Clipping Norm applied\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 5s 16us/step - loss: 0.2094 - mean_absolute_error: 0.3286\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2074 - mean_absolute_error: 0.3274\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2077 - mean_absolute_error: 0.3278\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 13us/step - loss: 0.2068 - mean_absolute_error: 0.3272\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 14us/step - loss: 0.2066 - mean_absolute_error: 0.3271\n",
      "44160/44160 [==============================] - 1s 28us/step\n",
      "Shape of org. dataset after shift:  (2208, 20)\n",
      "20/20 [==============================] - 0s 47us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## Avg. RMSE of recent predictions: \n",
      "[63.53539501160314]\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  3\n",
      ">> Current Time:  23/01/2020 14:23:43\n",
      "## Assigned Dates are double checked..\n",
      "Stop retraining scheme >> end of data set or end of predictions are reached\n",
      " >> Number of predictions with existing model:  1\n",
      " >> Number of retrainings:  3\n"
     ]
    }
   ],
   "source": [
    "#set model_name based on used params:\n",
    "model_name = 'complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_update_weights_quarterly'\n",
    "\n",
    "\n",
    "#create instance of class:\n",
    "cplxMLP_model_new = create_model_instance('ComplexMLP')\n",
    "\n",
    "#update instance with model from disk:\n",
    "prediction_model = load_pretrained_model_from_disk('ComplexMLP')\n",
    "cplxMLP_model_new.load_model(prediction_model)\n",
    "\n",
    "#set dataset for slicing:\n",
    "ts_series_input = ts_20largest.copy()\n",
    "\n",
    "\n",
    "\n",
    "#call function for drift detection & retraining:\n",
    "results_tuple_MLP_w_update = rrc.regular_retraining_scheme(cplxMLP_model_new, org_ts_series=ts_series_input, model_name=model_name, \n",
    "                                          n_epochs_weight = 5, overwrite_params = True,\n",
    "                                          update_weights_flag = True,\n",
    "                                          start_date_training = '2009', last_date_training = '2010', \n",
    "                                          first_date_dataset = '2009-01-01 00:00:00',\n",
    "                                          start_of_preds_date = '2011-01-01 00:00:00',\n",
    "                                          end_of_dataset_date = '2011-12-31 23:00:00',\n",
    "                                          forecast_range_months = 3, \n",
    "                                          retrain_shifting_window_months = 3,\n",
    "                                          month_forecasting = True,\n",
    "                                          retrain_shifting_window_flag_day = False,\n",
    "                                          retraining_range_years = 2,\n",
    "                                          first_preds_flag = False,           \n",
    "                                          verbosity=1)\n",
    "                               \n",
    "\n",
    "      \n",
    "    \n",
    "all_cplxMLP_MODELS_dict_w_update = results_tuple_MLP_w_update[0]\n",
    "all_cplxMLP_RESULTS_dict_w_update = results_tuple_MLP_w_update[1]\n",
    "all_cplxMLP_RMSE_results_w_update = results_tuple_MLP_w_update[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly Retraining of existing models.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplexMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy: training of new model on a yearly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T13:21:49.928175Z",
     "start_time": "2020-01-23T13:21:09.701587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting based on given months is used...\n",
      "Shifting Window based on given months is used:  12\n",
      "Retraining range based on years:  2\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  7\n",
      ">> Current Time:  23/01/2020 14:21:10\n",
      "## Assigned Dates are double checked..\n",
      "# Start training new model and make predictions..\n",
      "selected years for training:  [Timestamp('2010-01-01 00:00:00'), Timestamp('2011-12-31 23:00:00')]\n",
      "year_list given:  [Timestamp('2010-01-01 00:00:00'), Timestamp('2011-12-31 23:00:00'), Timestamp('2012-01-01 00:00:00'), None]\n",
      "#### Train model: complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_yearly__trainsize729_s1_2010_e12_2011__stepsize1__p12_2012 ####\n",
      "Keras Model is used...\n",
      "#params are overwritten\n",
      "## New Model is created, old model is discarded..\n",
      "create MLP Model:\n",
      "#Dropout applied\n",
      "#Clipping Norm applied\n",
      "Train on 336940 samples, validate on 102240 samples\n",
      "Epoch 1/5\n",
      "336940/336940 [==============================] - 6s 17us/step - loss: 0.3630 - mean_absolute_error: 0.4352 - val_loss: 0.2633 - val_mean_absolute_error: 0.3635\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 2/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2870 - mean_absolute_error: 0.3861 - val_loss: 0.2427 - val_mean_absolute_error: 0.3480\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 3/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2681 - mean_absolute_error: 0.3726 - val_loss: 0.2316 - val_mean_absolute_error: 0.3382\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 4/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2579 - mean_absolute_error: 0.3645 - val_loss: 0.2257 - val_mean_absolute_error: 0.3342\n",
      "#Current LearningRate:  0.001\n",
      "Epoch 5/5\n",
      "336940/336940 [==============================] - 5s 15us/step - loss: 0.2491 - mean_absolute_error: 0.3583 - val_loss: 0.2177 - val_mean_absolute_error: 0.3278\n",
      "#Current LearningRate:  0.001\n",
      "102240/102240 [==============================] - 3s 29us/step\n",
      "Shape of org. dataset after shift:  (5112, 20)\n",
      "20/20 [==============================] - 0s 53us/step\n",
      "Shape of org. dataset after shift:  (1, 20)\n",
      "## New model is trained and predictions are made..\n",
      "months to predict:  7\n",
      ">> Current Time:  23/01/2020 14:21:49\n",
      "## Assigned Dates are double checked..\n",
      "Stop retraining scheme >> end of data set or end of predictions are reached\n",
      " >> Number of predictions with existing model:  0\n",
      " >> Number of retrainings:  1\n"
     ]
    }
   ],
   "source": [
    "#set model_name based on used params:\n",
    "model_name = 'complex_MLP_2H_128_32_batch512_drop03_clip_norm_shuffle_scaling_std_W168_20largest_areas_reg_retrain_yearly'\n",
    "\n",
    "\n",
    "#create instance of class:\n",
    "cplxMLP_model_new = create_model_instance('ComplexMLP')\n",
    "\n",
    "#update instance with model from disk:\n",
    "prediction_model = load_pretrained_model_from_disk('ComplexMLP')\n",
    "cplxMLP_model_new.load_model(prediction_model)\n",
    "\n",
    "#set dataset for slicing:\n",
    "ts_series_input = ts_20largest.copy()\n",
    "\n",
    "\n",
    "\n",
    "#call function for drift detection & retraining:\n",
    "results_tuple_MLP_retrain_yearly = rrc.regular_retraining_scheme(cplxMLP_model_new, org_ts_series=ts_series_input, model_name=model_name, \n",
    "                                          n_epochs_retrain = 5, update_weights_flag = False, overwrite_params = True,\n",
    "                                          start_date_training = '2009', last_date_training = '2010', \n",
    "                                          first_date_dataset = '2009-01-01 00:00:00',\n",
    "                                          start_of_preds_date = '2011-01-01 00:00:00',\n",
    "                                          end_of_dataset_date = '2012-12-31 23:00:00',\n",
    "                                          forecast_range_months = 7, \n",
    "                                          retrain_shifting_window_months = 12,\n",
    "                                          month_forecasting = True,\n",
    "                                          retrain_shifting_window_flag_day = False,\n",
    "                                          retraining_range_years = 2,\n",
    "                                          first_preds_flag = True,           \n",
    "                                          verbosity=0)\n",
    "                               \n",
    "\n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
